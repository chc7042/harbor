const express = require('express');
const { authenticateToken } = require('../middleware/authSimple');
const { body, query, param, validationResult } = require('express-validator');
const { AppError } = require('../middleware/error');
const logger = require('../config/logger');
const { getJenkinsService } = require('../services/jenkinsService');
const { getNASService } = require('../services/nasService');
const { getDeploymentPathService } = require('../services/deploymentPathService');

const router = express.Router();


// ëª¨ë“  ë°°í¬ ë¼ìš°íŠ¸ëŠ” ì¸ì¦ í•„ìš”
router.use(authenticateToken);

/**
 * @swagger
 * /api/deployments:
 *   get:
 *     tags:
 *       - Deployments
 *     summary: ë°°í¬ ì´ë ¥ ëª©ë¡ ì¡°íšŒ
 *     description: í•„í„°ë§ ë° í˜ì´ì§€ë„¤ì´ì…˜ì„ ì§€ì›í•˜ëŠ” ë°°í¬ ì´ë ¥ ëª©ë¡ ì¡°íšŒ
 *     security:
 *       - bearerAuth: []
 *     parameters:
 *       - in: query
 *         name: page
 *         schema:
 *           type: integer
 *           minimum: 1
 *           default: 1
 *         description: í˜ì´ì§€ ë²ˆí˜¸
 *       - in: query
 *         name: limit
 *         schema:
 *           type: integer
 *           minimum: 1
 *           maximum: 100
 *           default: 20
 *         description: í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜
 *       - in: query
 *         name: project
 *         schema:
 *           type: string
 *         description: í”„ë¡œì íŠ¸ëª… í•„í„°
 *       - in: query
 *         name: environment
 *         schema:
 *           type: string
 *           enum: [development, staging, production]
 *         description: í™˜ê²½ í•„í„°
 *       - in: query
 *         name: status
 *         schema:
 *           type: string
 *           enum: [pending, in_progress, success, failed, cancelled]
 *         description: ìƒíƒœ í•„í„°
 *       - in: query
 *         name: search
 *         schema:
 *           type: string
 *         description: ê²€ìƒ‰ì–´ (í”„ë¡œì íŠ¸ëª…, ë¸Œëœì¹˜, ì»¤ë°‹ í•´ì‹œ)
 *       - in: query
 *         name: startDate
 *         schema:
 *           type: string
 *           format: date
 *         description: ì‹œì‘ ë‚ ì§œ í•„í„°
 *       - in: query
 *         name: endDate
 *         schema:
 *           type: string
 *           format: date
 *         description: ì¢…ë£Œ ë‚ ì§œ í•„í„°
 *     responses:
 *       200:
 *         description: ë°°í¬ ëª©ë¡ ì¡°íšŒ ì„±ê³µ
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 success:
 *                   type: boolean
 *                   example: true
 *                 data:
 *                   type: object
 *                   properties:
 *                     deployments:
 *                       type: array
 *                       items:
 *                         $ref: '#/components/schemas/Deployment'
 *                     pagination:
 *                       type: object
 *                       properties:
 *                         page:
 *                           type: integer
 *                         limit:
 *                           type: integer
 *                         total:
 *                           type: integer
 *                         totalPages:
 *                           type: integer
 *       400:
 *         description: ì˜ëª»ëœ ìš”ì²­ íŒŒë¼ë¯¸í„°
 *         content:
 *           application/json:
 *             schema:
 *               $ref: '#/components/schemas/Error'
 *       401:
 *         description: ì¸ì¦ ì‹¤íŒ¨
 *         content:
 *           application/json:
 *             schema:
 *               $ref: '#/components/schemas/Error'
 */
router.get('/',
  [
    query('page').optional().isInt({ min: 1 }).withMessage('í˜ì´ì§€ëŠ” 1 ì´ìƒì˜ ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤'),
    query('limit').optional().isInt({ min: 1, max: 100 }).withMessage('í•œ í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜ëŠ” 1-100 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤'),
    query('project').optional().isString().withMessage('í”„ë¡œì íŠ¸ëª…ì€ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤'),
    query('environment').optional().isIn(['development', 'staging', 'production']).withMessage('ìœ íš¨í•˜ì§€ ì•Šì€ í™˜ê²½ì…ë‹ˆë‹¤'),
    query('status').optional().isIn(['pending', 'in_progress', 'success', 'failed', 'cancelled']).withMessage('ìœ íš¨í•˜ì§€ ì•Šì€ ìƒíƒœì…ë‹ˆë‹¤'),
    query('search').optional().isString().withMessage('ê²€ìƒ‰ì–´ëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤'),
  ],
  async (req, res, next) => {
    try {
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        throw new AppError('ìœ íš¨í•˜ì§€ ì•Šì€ ìš”ì²­ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.', 400, errors.array());
      }

      const {
        page = 1,
        limit = 20,
        project,
        environment,
        status,
        search,
        startDate,
        endDate,
      } = req.query;

      const jenkinsService = getJenkinsService();

      try {
        // Jenkinsì—ì„œ ëª¨ë“  ì‘ì—… ëª©ë¡ ì¡°íšŒ
        const jobs = await jenkinsService.getJobs();

        // Jenkins job êµ¬ì¡° ë¶„ì„ ë° ê·¸ë£¹í•‘
        const groupedJobs = groupJobsByVersion(jobs);
        logger.info(`Grouped ${jobs.length} jobs into ${Object.keys(groupedJobs).length} version groups`);

        // ê° ë²„ì „ ê·¸ë£¹ì˜ ë¹Œë“œ ì´ë ¥ ì¡°íšŒ
        let allBuilds = [];

        for (const [version, jobGroup] of Object.entries(groupedJobs)) {
          try {
            // í”„ë¡œì íŠ¸ í•„í„°ë§
            if (project && !version.toLowerCase().includes(project.toLowerCase())) {
              continue;
            }

            // ë²„ì „ ê·¸ë£¹ì˜ ë°°í¬ ìƒíƒœ ê²°ì •
            const versionDeployment = await processVersionGroup(jenkinsService, version, jobGroup);
            if (versionDeployment) {
              allBuilds.push(versionDeployment);
            }
          } catch (error) {
            logger.warn(`Failed to process version group ${version}:`, error.message);

            // ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš°ì—ë„ ë²„ì „ ì •ë³´ëŠ” í‘œì‹œ
            const versionEntry = {
              id: `${version}-error`,
              projectName: version,
              buildNumber: null,
              status: 'error',
              timestamp: new Date(),
              duration: null,
              displayName: `${version} (ì˜¤ë¥˜)`,
              url: null,
              parameters: {},
              changes: [],
              environment: 'unknown',
              version: version,
              subJobs: [],
            };

            if (!search || version.toLowerCase().includes(search.toLowerCase())) {
              allBuilds.push(versionEntry);
            }
          }
        }

        // ê°œë³„ ì‘ì—…ë“¤ë„ ì²˜ë¦¬ (ë²„ì „ ê·¸ë£¹ì— ì†í•˜ì§€ ì•ŠëŠ” ê²½ìš°)
        for (const job of jobs) {
          try {
            // ì´ë¯¸ ë²„ì „ ê·¸ë£¹ì—ì„œ ì²˜ë¦¬ëœ jobì€ ê±´ë„ˆë›°ê¸°
            const isPartOfVersionGroup = Object.values(groupedJobs).some(group =>
              group.mrJob?.name === job.name || group.fsJob?.name === job.name,
            );
            if (isPartOfVersionGroup) continue;

            // í”„ë¡œì íŠ¸ í•„í„°ë§
            if (project && !job.name.toLowerCase().includes(project.toLowerCase())) {
              continue;
            }

            const builds = await jenkinsService.getJobBuilds(job.name, 50);

            if (builds.length === 0) {
              // ë¹Œë“œê°€ ì—†ëŠ” ê²½ìš° í”„ë¡œì íŠ¸ ì •ë³´ë§Œìœ¼ë¡œ ê¸°ë³¸ ì—”íŠ¸ë¦¬ ìƒì„± (updated)
              const projectEntry = {
                id: `${job.name}-placeholder`,
                projectName: job.name,
                buildNumber: null,
                status: 'no_builds',
                timestamp: new Date(),
                duration: null,
                displayName: `${job.name} (ë¹Œë“œ ì—†ìŒ)`,
                url: job.url,
                parameters: {},
                changes: [],
                environment: 'unknown',
                version: job.name, // í”„ë¡œì íŠ¸ ì´ë¦„ì„ ë²„ì „ìœ¼ë¡œ ì‚¬ìš©
                subJobs: [],
              };

              // ê²€ìƒ‰ í•„í„° ì ìš©
              if (search) {
                const searchLower = search.toLowerCase();
                if (!job.name.toLowerCase().includes(searchLower)) {
                  continue;
                }
              }

              allBuilds.push(projectEntry);
              continue;
            }

            // í•„í„°ë§ ì ìš©
            const filteredBuilds = builds.filter(build => {
              // í™˜ê²½ í•„í„°
              if (environment) {
                const buildEnv = determineEnvironment(build.projectName, build.parameters);
                if (buildEnv !== environment) return false;
              }

              // ìƒíƒœ í•„í„°
              if (status && build.status !== status) return false;

              // ê²€ìƒ‰ í•„í„°
              if (search) {
                const searchLower = search.toLowerCase();
                if (!build.projectName.toLowerCase().includes(searchLower) &&
                    !build.changes.some(change => change.message.toLowerCase().includes(searchLower))) {
                  return false;
                }
              }

              // ë‚ ì§œ í•„í„°
              if (startDate && new Date(build.timestamp) < new Date(startDate)) return false;
              if (endDate && new Date(build.timestamp) > new Date(endDate)) return false;

              return true;
            });

            allBuilds = allBuilds.concat(filteredBuilds);
          } catch (error) {
            logger.warn(`Failed to fetch builds for job ${job.name}:`, error.message);

            // ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš°ì—ë„ í”„ë¡œì íŠ¸ ì •ë³´ëŠ” í‘œì‹œ
            const projectEntry = {
              id: `${job.name}-error`,
              projectName: job.name,
              buildNumber: null,
              status: 'error',
              timestamp: new Date(),
              duration: null,
              displayName: `${job.name} (ì˜¤ë¥˜)`,
              url: job.url,
              parameters: {},
              changes: [],
              environment: 'unknown',
              version: job.name,
              subJobs: [],
            };

            if (!search || job.name.toLowerCase().includes(search.toLowerCase())) {
              allBuilds.push(projectEntry);
            }
          }
        }

        // ì‹œê°„ìˆœ ì •ë ¬
        allBuilds.sort((a, b) => new Date(b.timestamp) - new Date(a.timestamp));

        // í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©
        const totalItems = allBuilds.length;
        const totalPages = Math.ceil(totalItems / limit);
        const startIndex = (page - 1) * limit;
        const endIndex = startIndex + parseInt(limit);
        const paginatedBuilds = allBuilds.slice(startIndex, endIndex);

        // ì•„í‹°íŒ©íŠ¸ ì •ë³´ë¥¼ ì§€ì—° ë¡œë”©ìœ¼ë¡œ ë³€ê²½ - N+1 ì¿¼ë¦¬ ë¬¸ì œ í•´ê²°
        const deployments = paginatedBuilds.map((build) => {
          return {
            id: build.id,
            projectName: build.projectName,
            environment: determineEnvironment(build.projectName, build.parameters),
            version: build.parameters?.VERSION || build.parameters?.TAG || build.version || `build-${build.buildNumber}`,
            status: build.status,
            deployedBy: build.changes?.length > 0 ? build.changes[0].author : 'Jenkins',
            deployedAt: build.timestamp,
            duration: build.duration,
            buildNumber: build.buildNumber,
            jenkinsUrl: build.url,
            branch: build.parameters?.BRANCH_NAME || build.parameters?.GIT_BRANCH ||
                   (build.projectName && build.projectName.includes('_release') ?
                    build.projectName.split('/').pop().replace(/_(release|build)$/, '') : 'main'),
            commitHash: build.changes?.length > 0 ? build.changes[0].commitId : null,
            commitMessage: build.changes?.length > 0 ? build.changes[0].message : null,
            subJobs: build.subJobs || [],
            // ì•„í‹°íŒ©íŠ¸ ì •ë³´ëŠ” ì§€ì—° ë¡œë”©ìœ¼ë¡œ ì²˜ë¦¬ - ë³„ë„ API ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì œê³µ
            artifacts: [], // ê¸°ë³¸ê°’ìœ¼ë¡œ ë¹ˆ ë°°ì—´
            hasArtifacts: (build.status === 'success' || build.status === 'SUCCESS'), // ì•„í‹°íŒ©íŠ¸ ì¡´ì¬ ì—¬ë¶€ë§Œ í‘œì‹œ
          };
        });

        logger.info(`ë°°í¬ ëª©ë¡ ì¡°íšŒ - ì‚¬ìš©ì: ${req.user.username}, í˜ì´ì§€: ${page}, Jenkins ë°ì´í„°: ${deployments.length}ê°œ`);

        res.json({
          success: true,
          data: deployments,
          pagination: {
            currentPage: parseInt(page),
            totalPages,
            totalItems,
            itemsPerPage: parseInt(limit),
            hasNext: page < totalPages,
            hasPrevious: page > 1,
          },
        });

      } catch (jenkinsError) {
        logger.error('Jenkins API í˜¸ì¶œ ì‹¤íŒ¨, mock ë°ì´í„° ì‚¬ìš©:', jenkinsError.message);

        // Jenkins ì—°ê²° ì‹¤íŒ¨ ì‹œ mock ë°ì´í„° ë°˜í™˜
        const mockDeployments = {
          data: [
            {
              id: 1,
              projectName: 'jenkins-connection-failed',
              environment: 'development',
              version: 'mock-v1.0.0',
              status: 'failed',
              deployedBy: 'Mock User',
              deployedAt: new Date().toISOString(),
              duration: 180,
              buildNumber: 999,
              branch: 'main',
              error: 'Jenkins API ì—°ê²° ì‹¤íŒ¨',
            },
          ],
          pagination: {
            currentPage: parseInt(page),
            totalPages: 1,
            totalItems: 1,
            itemsPerPage: parseInt(limit),
            hasNext: false,
            hasPrevious: false,
          },
        };

        res.json({
          success: true,
          data: mockDeployments.data,
          pagination: mockDeployments.pagination,
          warning: 'Jenkins ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ mock ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.',
        });
      }
    } catch (error) {
      next(error);
    }
  },
);

// ìµœê·¼ ë°°í¬ ëª©ë¡ ì¡°íšŒ
router.get('/recent',
  [
    query('hours').optional().custom((value) => {
      if (value === null || value === undefined || value === '') return true;
      const numValue = parseInt(value);
      if (isNaN(numValue) || numValue < 1) {
        throw new Error('ì‹œê°„ì€ ì–‘ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤');
      }
      return true;
    }),
    query('limit').optional().isInt({ min: 1, max: 1000 }).withMessage('í•œ í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜ëŠ” 1-1000 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤'),
    query('page').optional().isInt({ min: 1 }).withMessage('í˜ì´ì§€ ë²ˆí˜¸ëŠ” 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤'),
    query('sort').optional().isString(),
    query('order').optional().isIn(['asc', 'desc']).withMessage('ì •ë ¬ ìˆœì„œëŠ” asc ë˜ëŠ” descì—¬ì•¼ í•©ë‹ˆë‹¤'),
  ],
  async (req, res, next) => {
    try {
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        throw new AppError('ìœ íš¨í•˜ì§€ ì•Šì€ ìš”ì²­ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.', 400, errors.array());
      }

      const {
        hours,
        limit = 5,
        page = 1,
        sort = 'created_at',
        order = 'desc',
        ...otherParams
      } = req.query;

      const jenkinsService = getJenkinsService();

      try {
        // hoursê°€ null, undefinedì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ë¬´ì œí•œìœ¼ë¡œ ì„¤ì •
        const timeLimit = (hours === null || hours === undefined || hours === 'null' || hours === '') ? null : parseInt(hours);
        // í˜ì´ì§€ë„¤ì´ì…˜ì„ ìœ„í•´ ë” ë§ì€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ í›„ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í˜ì´ì§• ì²˜ë¦¬
        const fetchLimit = timeLimit === null ? 10000 : Math.max(parseInt(limit) * parseInt(page), 100);

        // Jenkinsì—ì„œ ìµœê·¼ ë¹Œë“œ ì¡°íšŒ
        const recentBuilds = await jenkinsService.getRecentBuilds(timeLimit, fetchLimit);

        const recentDeployments = recentBuilds.map(build => ({
          id: build.id,
          projectName: build.projectName,
          environment: determineEnvironment(build.projectName, build.parameters),
          version: build.parameters?.VERSION || build.parameters?.TAG || `build-${build.buildNumber}`,
          status: build.status,
          deployedBy: build.changes && build.changes.length > 0 ? build.changes[0].author : 'Jenkins',
          deployedAt: build.timestamp,
          duration: build.duration,
          buildNumber: build.buildNumber,
          jenkinsUrl: build.url,
          branch: build.parameters?.BRANCH_NAME || build.parameters?.GIT_BRANCH ||
                 (build.projectName && build.projectName.includes('_release') ?
                  build.projectName.split('/').pop().replace(/_(release|build)$/, '') : 'main'),
          commitHash: build.changes && build.changes.length > 0 ? build.changes[0].commitId : null,
          commitMessage: build.changes && build.changes.length > 0 ? build.changes[0].message : null,
        }));

        // í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬
        const totalItems = recentDeployments.length;
        const totalPages = Math.ceil(totalItems / parseInt(limit));
        const startIndex = (parseInt(page) - 1) * parseInt(limit);
        const endIndex = startIndex + parseInt(limit);
        const paginatedDeployments = recentDeployments.slice(startIndex, endIndex);

        logger.info(`ìµœê·¼ ë°°í¬ ëª©ë¡ ì¡°íšŒ - ì‚¬ìš©ì: ${req.user?.username || 'unknown'}, ì‹œê°„: ${timeLimit || 'ë¬´ì œí•œ'}h, í˜ì´ì§€: ${page}/${totalPages}, Jenkins ë°ì´í„°: ${paginatedDeployments.length}/${totalItems}ê°œ`);

        res.json({
          success: true,
          data: paginatedDeployments,
          pagination: {
            currentPage: parseInt(page),
            totalPages: totalPages,
            totalItems: totalItems,
            itemsPerPage: parseInt(limit),
            hasNext: parseInt(page) < totalPages,
            hasPrevious: parseInt(page) > 1,
          },
        });

      } catch (jenkinsError) {
        logger.error('Jenkins API í˜¸ì¶œ ì‹¤íŒ¨, mock ë°ì´í„° ì‚¬ìš©:', jenkinsError.message);

        // Jenkins ì—°ê²° ì‹¤íŒ¨ ì‹œ mock ë°ì´í„° ë°˜í™˜
        const mockRecentDeployments = [
          {
            id: 1,
            projectName: 'jenkins-connection-failed',
            environment: 'development',
            version: 'mock-v1.0.0',
            status: 'failed',
            deployedBy: 'Mock User',
            deployedAt: new Date(Date.now() - 1000 * 60 * 30).toISOString(),
            duration: 180,
            buildNumber: 999,
            branch: 'main',
            error: 'Jenkins API ì—°ê²° ì‹¤íŒ¨',
          },
        ];

        // Mock ë°ì´í„°ì—ë„ í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©
        const totalItems = mockRecentDeployments.length;
        const totalPages = Math.ceil(totalItems / parseInt(limit));
        const startIndex = (parseInt(page) - 1) * parseInt(limit);
        const endIndex = startIndex + parseInt(limit);
        const paginatedMockDeployments = mockRecentDeployments.slice(startIndex, endIndex);

        res.json({
          success: true,
          data: paginatedMockDeployments,
          pagination: {
            currentPage: parseInt(page),
            totalPages: totalPages,
            totalItems: totalItems,
            itemsPerPage: parseInt(limit),
            hasNext: parseInt(page) < totalPages,
            hasPrevious: parseInt(page) > 1,
          },
          warning: 'Jenkins ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ mock ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.',
        });
      }
    } catch (error) {
      next(error);
    }
  },
);

// íŠ¹ì • ë°°í¬ ìƒì„¸ ì¡°íšŒ
router.get('/:id',
  [
    param('id').isInt({ min: 1 }).withMessage('ë°°í¬ IDëŠ” ì–‘ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤'),
  ],
  async (req, res, next) => {
    try {
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        throw new AppError('ìœ íš¨í•˜ì§€ ì•Šì€ ë°°í¬ IDì…ë‹ˆë‹¤.', 400, errors.array());
      }

      const { id } = req.params;

      // TODO: ì‹¤ì œ ë°°í¬ ìƒì„¸ ì¡°íšŒ ë¡œì§ êµ¬í˜„
      // const deployment = await deploymentService.getDeploymentById(id);

      // ì„ì‹œ ë°ì´í„°
      const mockDeployment = {
        id: parseInt(id),
        projectName: 'jenkins-nas-deployment-history',
        environment: 'production',
        version: 'v1.0.0',
        status: 'success',
        deployedBy: 'í™ê¸¸ë™',
        deployedAt: new Date().toISOString(),
        duration: 180,
        buildNumber: 42,
        commitHash: 'abc123def456',
        commitMessage: 'feat: Add deployment history feature',
        jenkinsUrl: 'http://jenkins.internal:8080/job/deploy-nas/42/',
        logs: [
          { timestamp: new Date().toISOString(), level: 'INFO', message: 'ë°°í¬ ì‹œì‘' },
          { timestamp: new Date().toISOString(), level: 'INFO', message: 'Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘...' },
          { timestamp: new Date().toISOString(), level: 'SUCCESS', message: 'ë°°í¬ ì™„ë£Œ' },
        ],
      };

      logger.info(`ë°°í¬ ìƒì„¸ ì¡°íšŒ - ì‚¬ìš©ì: ${req.user.username}, ë°°í¬ ID: ${id}`);

      res.json({
        success: true,
        data: mockDeployment,
      });
    } catch (error) {
      next(error);
    }
  },
);

// ë°°í¬ ì¬ì‹œì‘
router.post('/:id/restart',
  [
    param('id').isInt({ min: 1 }).withMessage('ë°°í¬ IDëŠ” ì–‘ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤'),
  ],
  async (req, res, next) => {
    try {
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        throw new AppError('ìœ íš¨í•˜ì§€ ì•Šì€ ë°°í¬ IDì…ë‹ˆë‹¤.', 400, errors.array());
      }

      const { id } = req.params;

      // TODO: ì‹¤ì œ ë°°í¬ ì¬ì‹œì‘ ë¡œì§ êµ¬í˜„
      // const result = await deploymentService.restartDeployment(id, req.user.id);

      logger.info(`ë°°í¬ ì¬ì‹œì‘ ìš”ì²­ - ì‚¬ìš©ì: ${req.user.username}, ë°°í¬ ID: ${id}`);

      res.json({
        success: true,
        message: 'ë°°í¬ ì¬ì‹œì‘ì´ ìš”ì²­ë˜ì—ˆìŠµë‹ˆë‹¤.',
        data: {
          deploymentId: parseInt(id),
          status: 'pending',
          requestedBy: req.user.username,
          requestedAt: new Date().toISOString(),
        },
      });
    } catch (error) {
      next(error);
    }
  },
);

// ë°°í¬ ì·¨ì†Œ
router.post('/:id/cancel',
  [
    param('id').isInt({ min: 1 }).withMessage('ë°°í¬ IDëŠ” ì–‘ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤'),
  ],
  async (req, res, next) => {
    try {
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        throw new AppError('ìœ íš¨í•˜ì§€ ì•Šì€ ë°°í¬ IDì…ë‹ˆë‹¤.', 400, errors.array());
      }

      const { id } = req.params;

      // TODO: ì‹¤ì œ ë°°í¬ ì·¨ì†Œ ë¡œì§ êµ¬í˜„
      // const result = await deploymentService.cancelDeployment(id, req.user.id);

      logger.info(`ë°°í¬ ì·¨ì†Œ ìš”ì²­ - ì‚¬ìš©ì: ${req.user.username}, ë°°í¬ ID: ${id}`);

      res.json({
        success: true,
        message: 'ë°°í¬ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.',
        data: {
          deploymentId: parseInt(id),
          status: 'cancelled',
          cancelledBy: req.user.username,
          cancelledAt: new Date().toISOString(),
        },
      });
    } catch (error) {
      next(error);
    }
  },
);

// Jenkins ë°°í¬ ë¡œê·¸ ì¡°íšŒ
router.get('/logs/*',
  async (req, res, next) => {
    try {
      // URL pathì—ì„œ projectNameê³¼ buildNumber ì¶”ì¶œ
      const pathParts = req.params[0].split('/');
      const buildNumber = pathParts.pop(); // ë§ˆì§€ë§‰ ë¶€ë¶„ì´ buildNumber
      const projectName = pathParts.join('/'); // ë‚˜ë¨¸ì§€ê°€ projectName

      // ê¸°ë³¸ ìœ íš¨ì„± ê²€ì‚¬
      if (!projectName || !buildNumber || isNaN(parseInt(buildNumber))) {
        throw new AppError('ìœ íš¨í•˜ì§€ ì•Šì€ ìš”ì²­ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤. ì˜¬ë°”ë¥¸ í˜•ì‹: /logs/{projectName}/{buildNumber}', 400);
      }

      // TEMP: TEST ìš©ë„ë¡œ ì¸ì¦ ìš°íšŒ

      const jenkinsService = getJenkinsService();

      try {
        // Jenkinsì—ì„œ ë¹Œë“œ ë¡œê·¸ ì¡°íšŒ
        const logs = await jenkinsService.getBuildLog(projectName, buildNumber);

        logger.info(`Jenkins ë¹Œë“œ ë¡œê·¸ ì¡°íšŒ - ì‚¬ìš©ì: ${req.user.username}, í”„ë¡œì íŠ¸: ${projectName}, ë¹Œë“œ: ${buildNumber}`);

        res.json({
          success: true,
          data: logs,
        });

      } catch (jenkinsError) {
        logger.error('Jenkins ë¹Œë“œ ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨, mock ë°ì´í„° ì‚¬ìš©:', jenkinsError.message);

        // Jenkins ì—°ê²° ì‹¤íŒ¨ ì‹œ mock ë°ì´í„° ë°˜í™˜
        const mockLogs = [
          { timestamp: '2025-09-29 12:30:01', level: 'INFO', message: `[${projectName}#${buildNumber}] ğŸš€ Starting Jenkins deployment process...` },
          { timestamp: '2025-09-29 12:30:03', level: 'INFO', message: `[${projectName}#${buildNumber}] ğŸ“¥ Fetching code from Git repository` },
          { timestamp: '2025-09-29 12:30:05', level: 'INFO', message: `[${projectName}#${buildNumber}] ğŸ” Checking out mr3.0.0 release branch` },
          { timestamp: '2025-09-29 12:30:12', level: 'INFO', message: `[${projectName}#${buildNumber}] ğŸ”¨ Building mr3.0.0 release package` },
          { timestamp: '2025-09-29 12:30:25', level: 'INFO', message: `[${projectName}#${buildNumber}] ğŸ§ª Running unit tests for mr3.0.0` },
          { timestamp: '2025-09-29 12:30:38', level: 'INFO', message: `[${projectName}#${buildNumber}] âœ… All tests passed for mr3.0.0` },
          { timestamp: '2025-09-29 12:30:42', level: 'INFO', message: `[${projectName}#${buildNumber}] ğŸ“¦ Creating mr3.0.0 release artifacts` },
          { timestamp: '2025-09-29 12:30:48', level: 'INFO', message: `[${projectName}#${buildNumber}] ğŸš€ Deploying mr3.0.0 to production environment` },
          { timestamp: '2025-09-29 12:30:55', level: 'SUCCESS', message: `[${projectName}#${buildNumber}] ğŸ‰ mr3.0.0 deployment completed successfully!` },
          { timestamp: '2025-09-29 12:30:56', level: 'INFO', message: 'âš ï¸  NOTE: This is MOCK DATA - Jenkins server is not reachable' },
        ];

        res.json({
          success: true,
          data: mockLogs,
          warning: 'Jenkins ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ mock ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.',
        });
      }
    } catch (error) {
      next(error);
    }
  },
);

// ë°°í¬ í†µê³„ ì¡°íšŒ
router.get('/stats/summary',
  async (req, res, next) => {
    try {
      // TODO: ì‹¤ì œ ë°°í¬ í†µê³„ ì¡°íšŒ ë¡œì§ êµ¬í˜„
      // const stats = await deploymentService.getDeploymentStats();

      // ì„ì‹œ ë°ì´í„°
      const mockStats = {
        totalDeployments: 1247,
        successfulDeployments: 1189,
        failedDeployments: 58,
        successRate: 95.3,
        averageDuration: 145,
        deploymentsToday: 12,
        deploymentsThisWeek: 87,
        deploymentsThisMonth: 342,
        topProjects: [
          { name: 'api-gateway', deployments: 89 },
          { name: 'user-service', deployments: 76 },
          { name: 'payment-service', deployments: 54 },
        ],
      };

      logger.info(`ë°°í¬ í†µê³„ ì¡°íšŒ - ì‚¬ìš©ì: ${req.user.username}`);

      res.json({
        success: true,
        data: mockStats,
      });
    } catch (error) {
      next(error);
    }
  },
);

// í—¬í¼ í•¨ìˆ˜ë“¤

/**
 * Jenkins jobë“¤ì„ ë²„ì „ë³„ë¡œ ê·¸ë£¹í•‘
 * ì˜ˆ: 1.2.0 â†’ { mrJob: '1.2.0/mr1.2.0_release', fsJob: '1.2.0/fs1.2.0_release' }
 */
function groupJobsByVersion(jobs) {
  const groups = {};

  for (const job of jobs) {
    // ë²„ì „ íŒ¨í„´ ë§¤ì¹­: x.x.x/mrx.x.x_release ë˜ëŠ” x.x.x/fsx.x.x_release
    const versionMatch = job.name.match(/^(\d+\.\d+\.\d+)\/(mr|fs)(\d+\.\d+\.\d+)_release$/);

    if (versionMatch) {
      const [, version, prefix, subVersion] = versionMatch;

      if (!groups[version]) {
        groups[version] = {
          version,
          mrJob: null,
          fsJob: null,
        };
      }

      if (prefix === 'mr') {
        groups[version].mrJob = job;
      } else if (prefix === 'fs') {
        groups[version].fsJob = job;
      }
    }
  }

  // ì™„ì „í•œ ê·¸ë£¹ë§Œ ë°˜í™˜ (mrê³¼ fs ëª¨ë‘ ìˆëŠ” ê²½ìš°)
  const completeGroups = {};
  for (const [version, group] of Object.entries(groups)) {
    if (group.mrJob && group.fsJob) {
      completeGroups[version] = group;
      logger.info(`Complete version group found: ${version} with mr and fs jobs`);
    }
  }

  return completeGroups;
}

/**
 * ë²„ì „ ê·¸ë£¹ì˜ ë°°í¬ ìƒíƒœ ì²˜ë¦¬
 * mr â†’ fs ìˆœì„œë¡œ ì§„í–‰ë˜ë©° ë‘˜ ë‹¤ ì„±ê³µí•´ì•¼ ì „ì²´ ì„±ê³µ
 */
async function processVersionGroup(jenkinsService, version, jobGroup) {
  try {
    // mr job ë¹Œë“œ ì¡°íšŒ
    const mrBuilds = await jenkinsService.getJobBuilds(jobGroup.mrJob.name, 10);
    const latestMrBuild = mrBuilds[0];

    // fs job ë¹Œë“œ ì¡°íšŒ
    const fsBuilds = await jenkinsService.getJobBuilds(jobGroup.fsJob.name, 10);
    const latestFsBuild = fsBuilds[0];

    if (!latestMrBuild && !latestFsBuild) {
      return null; // ë¹Œë“œê°€ ì—†ëŠ” ê²½ìš°
    }

    // ì „ì²´ ìƒíƒœ ê²°ì • ë¡œì§
    let overallStatus = 'pending';
    let timestamp = new Date();
    let duration = 0;
    let changes = [];
    let parameters = {};

    // mr â†’ fs ìˆœì„œ ê³ ë ¤í•œ ìƒíƒœ ê²°ì •
    if (latestMrBuild && latestFsBuild) {
      // ë‘˜ ë‹¤ ì„±ê³µí•œ ê²½ìš°ì—ë§Œ ì „ì²´ ì„±ê³µ
      if ((latestMrBuild.status === 'success' || latestMrBuild.status === 'SUCCESS') &&
          (latestFsBuild.status === 'success' || latestFsBuild.status === 'SUCCESS')) {
        overallStatus = 'success';
      } else if ((latestMrBuild.status === 'failed' || latestMrBuild.status === 'FAILED') ||
                 (latestFsBuild.status === 'failed' || latestFsBuild.status === 'FAILED')) {
        overallStatus = 'failed';
      } else {
        overallStatus = 'in_progress';
      }

      // ë” ìµœê·¼ ë¹Œë“œì˜ ì‹œê°„ ì‚¬ìš©
      timestamp = new Date(Math.max(new Date(latestMrBuild.timestamp), new Date(latestFsBuild.timestamp)));

      // duration ë””ë²„ê·¸ ë¡œê·¸ ì¶”ê°€
      logger.debug(`Duration calculation for ${version}: mr=${latestMrBuild.duration}s, fs=${latestFsBuild.duration}s`);

      // ë‘ ì‘ì—… ì¤‘ ë” ê¸´ ì‹œê°„ì„ ì‚¬ìš© (ìˆœì°¨ ì‹¤í–‰ì´ ì•„ë‹Œ ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ê°€ì •)
      duration = Math.max(latestMrBuild.duration || 0, latestFsBuild.duration || 0);

      changes = [...(latestMrBuild.changes || []), ...(latestFsBuild.changes || [])];
      parameters = { ...latestMrBuild.parameters, ...latestFsBuild.parameters };
    } else if (latestMrBuild) {
      // mrë§Œ ìˆëŠ” ê²½ìš°
      overallStatus = latestMrBuild.status === 'success' || latestMrBuild.status === 'SUCCESS' ? 'in_progress' : latestMrBuild.status;
      timestamp = new Date(latestMrBuild.timestamp);
      duration = latestMrBuild.duration || 0;
      changes = latestMrBuild.changes || [];
      parameters = latestMrBuild.parameters || {};
    } else if (latestFsBuild) {
      // fsë§Œ ìˆëŠ” ê²½ìš° (ë¹„ì •ìƒì ì´ì§€ë§Œ ì²˜ë¦¬)
      overallStatus = latestFsBuild.status;
      timestamp = new Date(latestFsBuild.timestamp);
      duration = latestFsBuild.duration || 0;
      changes = latestFsBuild.changes || [];
      parameters = latestFsBuild.parameters || {};
    }

    // ì„œë¸Œ ì¡ ì •ë³´ êµ¬ì„±
    const subJobs = [];
    if (latestMrBuild) {
      subJobs.push({
        name: jobGroup.mrJob.name,
        status: latestMrBuild.status,
        buildNumber: latestMrBuild.buildNumber,
        timestamp: latestMrBuild.timestamp,
        duration: latestMrBuild.duration,
        order: 1,
      });
    }
    if (latestFsBuild) {
      subJobs.push({
        name: jobGroup.fsJob.name,
        status: latestFsBuild.status,
        buildNumber: latestFsBuild.buildNumber,
        timestamp: latestFsBuild.timestamp,
        duration: latestFsBuild.duration,
        order: 2,
      });
    }

    return {
      id: `${version}-group`,
      projectName: version,
      buildNumber: null, // ê·¸ë£¹ì—ëŠ” ë‹¨ì¼ ë¹Œë“œ ë²ˆí˜¸ê°€ ì—†ìŒ
      status: overallStatus,
      timestamp: timestamp,
      duration: duration,
      displayName: `${version} (${subJobs.length}ê°œ ì‘ì—…)`,
      url: null,
      parameters: parameters,
      changes: changes,
      environment: determineEnvironment(version, parameters),
      version: version,
      subJobs: subJobs,
    };
  } catch (error) {
    logger.error(`Error processing version group ${version}:`, error);
    throw error;
  }
}

function determineEnvironment(jobName, parameters = {}) {
  const name = jobName.toLowerCase();

  // íŒŒë¼ë¯¸í„°ì—ì„œ í™˜ê²½ ì •ë³´ í™•ì¸
  if (parameters.ENVIRONMENT) {
    return parameters.ENVIRONMENT.toLowerCase();
  }

  if (parameters.DEPLOY_ENV) {
    return parameters.DEPLOY_ENV.toLowerCase();
  }

  // ì‘ì—… ì´ë¦„ì—ì„œ í™˜ê²½ ì¶”ì •
  if (name.includes('prod') || name.includes('production')) {
    return 'production';
  }

  if (name.includes('stag') || name.includes('staging')) {
    return 'staging';
  }

  if (name.includes('dev') || name.includes('development')) {
    return 'development';
  }

  return 'development';
}

// ê³µí†µ ë°°í¬ ì •ë³´ ì¡°íšŒ í•¨ìˆ˜
async function getDeploymentInfo(projectName, buildNumber, version = null, req) {
  const logger = require('../config/logger');
  const jenkinsService = getJenkinsService();
  const nasService = getNASService();
  const SynologyApiService = require('../services/synologyApiService');
  const synologyApiService = new SynologyApiService();

  logger.info(`ë°°í¬ ì •ë³´ ì¡°íšŒ ì‹œì‘ - í”„ë¡œì íŠ¸: ${projectName}, ë¹Œë“œ: ${buildNumber}, ë²„ì „: ${version}`);

  // 1. ë¨¼ì € deployment_paths í…Œì´ë¸”ì—ì„œ ê¸°ì¡´ ê²€ì¦ëœ ë°ì´í„° í™•ì¸ (ìµœì í™”ë¨)
  let deploymentInfo = null;
  try {
    logger.info(`DB ì¿¼ë¦¬ ì‹œë„ - í”„ë¡œì íŠ¸: ${projectName}, ë¹Œë“œ: ${buildNumber}`);
    const { query } = require('../config/database');

    const dbResult = await query(
      'SELECT * FROM deployment_paths WHERE project_name = $1 AND build_number = $2',
      [projectName, parseInt(buildNumber)],
    );

    logger.info(`DB ì¿¼ë¦¬ ê²°ê³¼ - í–‰ ê°œìˆ˜: ${dbResult.rows.length}`);

    if (dbResult.rows.length > 0) {
      const dbRecord = dbResult.rows[0];
      logger.info(`DB ë ˆì½”ë“œ ë°œê²¬ - all_files: ${JSON.stringify(dbRecord.all_files)}`);
      deploymentInfo = {
        deploymentPath: dbRecord.nas_path,
        nasPath: dbRecord.nas_path,
        downloadFile: dbRecord.download_file,
        allFiles: dbRecord.all_files || [],
        verifiedFiles: dbRecord.all_files || [],
        directoryVerified: true,
        downloadFileVerified: true,
        buildDate: dbRecord.build_date,
        buildNumber: dbRecord.build_number,
      };
      logger.info(`Found verified deployment data in database for ${projectName}#${buildNumber}`);
      logger.info(`DB allFiles: ${JSON.stringify(dbRecord.all_files)}`);

      // DBì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì€ ê²½ìš° Synology API í˜¸ì¶œ ê±´ë„ˆë›°ê¸°
      logger.info('DBì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì•˜ìœ¼ë¯€ë¡œ ë¹ ë¥¸ ì‘ë‹µ ì œê³µ');
    } else {
      logger.warn(`DBì—ì„œ ë ˆì½”ë“œë¥¼ ì°¾ì§€ ëª»í•¨ - ${projectName}#${buildNumber}`);
    }
  } catch (dbError) {
    logger.error(`Database query failed: ${dbError.message}`);
    logger.error(`DB ì—°ê²° ì •ë³´ - host: ${process.env.DB_HOST}, port: ${process.env.DB_PORT}, db: ${process.env.DB_NAME}, user: ${process.env.DB_USER}`);
  }

  // 2. DBì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ Jenkinsì—ì„œ ë™ì ìœ¼ë¡œ ì¡°íšŒ
  if (!deploymentInfo) {
    logger.info(`Jenkinsì—ì„œ ë°°í¬ ì •ë³´ ì¡°íšŒ - ${projectName}#${buildNumber}`);
    deploymentInfo = await jenkinsService.extractDeploymentInfo(projectName, parseInt(buildNumber));
  }

  return {
    success: true,
    data: deploymentInfo || { downloadFile: null, allFiles: [], artifacts: {} },
  };
}

// Jenkins ë°°í¬ ì •ë³´ ì¡°íšŒ (3-segment URL: version/projectName/buildNumber)
router.get('/deployment-info/:version/:projectName/:buildNumber',
  [
    param('version').isString().withMessage('ë²„ì „ì€ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤'),
    param('projectName').isString().withMessage('í”„ë¡œì íŠ¸ëª…ì€ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤'),
    param('buildNumber').isInt({ min: 1 }).withMessage('ë¹Œë“œ ë²ˆí˜¸ëŠ” ì–‘ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤'),
  ],
  async (req, res, next) => {
    try {
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        return res.status(400).json({
          success: false,
          message: 'ì…ë ¥ ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.',
          errors: errors.array(),
        });
      }

      const { version, projectName, buildNumber } = req.params;

      // ì‹¤ì œ projectNameì€ version/projectName ì¡°í•©
      const fullProjectName = `${version}/${projectName}`;

      logger.info(`ë°°í¬ ì •ë³´ ì¡°íšŒ ìš”ì²­ (3-segment) - ì‚¬ìš©ì: ${req.user.username}, ë²„ì „: ${version}, í”„ë¡œì íŠ¸: ${projectName}, ë¹Œë“œ: ${buildNumber}`);
      logger.info(`Full project name: ${fullProjectName}`);

      // ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©
      const result = await getDeploymentInfo(fullProjectName, buildNumber, version, req);
      
      return res.json({
        success: result.success,
        data: {
          projectName: fullProjectName,
          buildNumber: parseInt(buildNumber),
          status: 'SUCCESS',
          ...result.data
        }
      });

      const jenkinsService = getJenkinsService();
      const nasService = getNASService();
      const SynologyApiService = require('../services/synologyApiService');
      const synologyApiService = new SynologyApiService();

      try {
        logger.info(`ë°°í¬ ì •ë³´ ì¡°íšŒ ì‹œì‘ - í”„ë¡œì íŠ¸: ${fullProjectName}, ë¹Œë“œ: ${buildNumber}`);

        // 1. ë¨¼ì € deployment_paths í…Œì´ë¸”ì—ì„œ ê¸°ì¡´ ê²€ì¦ëœ ë°ì´í„° í™•ì¸ (ìµœì í™”ë¨)
        let deploymentInfo = null;
        try {
          logger.info(`DB ì¿¼ë¦¬ ì‹œë„ - í”„ë¡œì íŠ¸: ${fullProjectName}, ë¹Œë“œ: ${buildNumber}`);
          const { query } = require('../config/database');

          const dbResult = await query(
            'SELECT * FROM deployment_paths WHERE project_name = $1 AND build_number = $2',
            [fullProjectName, parseInt(buildNumber)],
          );

          logger.info(`DB ì¿¼ë¦¬ ê²°ê³¼ - í–‰ ê°œìˆ˜: ${dbResult.rows.length}`);

          if (dbResult.rows.length > 0) {
            const dbRecord = dbResult.rows[0];
            logger.info(`DB ë ˆì½”ë“œ ë°œê²¬ - all_files: ${JSON.stringify(dbRecord.all_files)}`);
            deploymentInfo = {
              deploymentPath: dbRecord.nas_path,
              nasPath: dbRecord.nas_path,
              downloadFile: dbRecord.download_file,
              allFiles: dbRecord.all_files || [],
              verifiedFiles: dbRecord.all_files || [],
              directoryVerified: true,
              downloadFileVerified: true,
              buildDate: dbRecord.build_date,
              buildNumber: dbRecord.build_number,
            };
            logger.info(`Found verified deployment data in database for ${fullProjectName}#${buildNumber}`);
            logger.info(`DB allFiles: ${JSON.stringify(dbRecord.all_files)}`);

            // DBì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì€ ê²½ìš° Synology API í˜¸ì¶œ ê±´ë„ˆë›°ê¸°
            if (false) {
              logger.info('DBì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì•˜ì§€ë§Œ Synology ê³µìœ  ë§í¬ê°€ ì—†ìŒ, ìƒì„± ì‹œë„');

              // ë²„ì „ ì •ë³´ ì¶”ì¶œ
              const extractedVersion = version.replace(/^(\d+\.\d+\.\d+).*/, '$1');
              let date = '';
              let buildNum = '';

              const dateMatch = fullProjectName.match(/_(\d{6})_/) || deploymentInfo.nasPath?.match(/\/(\d{6})\//);
              const buildMatch = fullProjectName.match(/_(\d+)$/) || deploymentInfo.nasPath?.match(/\/(\d+)$/);

              if (dateMatch) date = dateMatch[1];
              if (buildMatch) buildNum = buildMatch[1];

              // ê¸°ë³¸ê°’ ì„¤ì •
              if (!date) date = '250116'; // 2.0.0 ê¸°ë³¸ ë‚ ì§œ
              if (!buildNum) buildNum = buildNumber;

              logger.info(`ğŸ”— Synology API í˜¸ì¶œ ì‹œì‘ (DB ë°ì´í„° ë³´ì™„) - getOrCreateVersionShareLink(${extractedVersion}, ${date}, ${buildNum})`);
              try {
                const shareResult = await Promise.race([
                  synologyApiService.getOrCreateVersionShareLink(extractedVersion, date, buildNum),
                  new Promise((_, reject) => setTimeout(() => reject(new Error('Synology API timeout')), 3000)),
                ]);

                logger.info('ğŸ”— Synology API ì‘ë‹µ (DB ë°ì´í„° ë³´ì™„):', JSON.stringify(shareResult, null, 2));

                if (shareResult.success) {
                  deploymentInfo.synologyShareUrl = shareResult.shareUrl;
                  deploymentInfo.synologyShareId = shareResult.shareId;
                  deploymentInfo.shareCreated = shareResult.isNew;

                  logger.info(`Synology folder share link ${shareResult.isNew ? 'created' : 'found'} (DB ë°ì´í„° ë³´ì™„): ${shareResult.shareUrl}`);
                } else {
                  logger.warn(`Synology share link creation failed (DB ë°ì´í„° ë³´ì™„): ${shareResult.error}`);
                }
              } catch (shareError) {
                logger.warn(`Synology share link error (DB ë°ì´í„° ë³´ì™„): ${shareError.message}`);
              }
            } else {
              // DBì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì•˜ìœ¼ë¯€ë¡œ Synology API í˜¸ì¶œ ê±´ë„ˆë›°ê¸°
              logger.info('DBì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì•˜ìœ¼ë¯€ë¡œ ë¹ ë¥¸ ì‘ë‹µ ì œê³µ');
            }
          } else {
            logger.warn(`DBì—ì„œ ë ˆì½”ë“œë¥¼ ì°¾ì§€ ëª»í•¨ - ${fullProjectName}#${buildNumber}`);
          }
        } catch (dbError) {
          logger.error(`Database query failed: ${dbError.message}`);
          logger.error(`DB ì—°ê²° ì •ë³´ - host: ${process.env.DB_HOST}, port: ${process.env.DB_PORT}, db: ${process.env.DB_NAME}, user: ${process.env.DB_USER}`);
        }

        // 2. DBì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ Jenkinsì—ì„œ ë™ì ìœ¼ë¡œ ì¡°íšŒ
        if (!deploymentInfo) {
          // Jenkinsì—ì„œ ë¹Œë“œ ì •ë³´ í™•ì¸ - extractDeploymentInfoFromBuildLogë¥¼ í†µí•´ ìƒíƒœë„ í™•ì¸
          let buildStatus = null;
          try {
            logger.info(`Jenkins ë¹Œë“œ ë¡œê·¸ ì¶”ì¶œ ì‹œë„ - ${fullProjectName}#${buildNumber}`);
            // ë¹Œë“œ ë¡œê·¸ì—ì„œ ì •ë³´ë¥¼ ë¨¼ì € ì¶”ì¶œí•´ë³´ê³  ìƒíƒœ í™•ì¸
            const preliminaryInfo = await jenkinsService.extractDeploymentInfoFromBuildLog(fullProjectName, parseInt(buildNumber));
            buildStatus = 'SUCCESS'; // ë¡œê·¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìœ¼ë©´ ë¹Œë“œëŠ” ì™„ë£Œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
            logger.info(`Jenkins ë¹Œë“œ ë¡œê·¸ ì¶”ì¶œ ì„±ê³µ - ${fullProjectName}#${buildNumber}`);
          } catch (error) {
            logger.error(`ë¹Œë“œ ë¡œê·¸ ì ‘ê·¼ ì‹¤íŒ¨ - ${fullProjectName}#${buildNumber}: ${error.message}`);
            logger.error('Error stack:', error.stack);
            buildStatus = 'UNKNOWN';
          }

          // Jenkinsì—ì„œ ë°°í¬ ì •ë³´ ì¡°íšŒ (PRD ê¸°ë°˜ ìë™ ê²½ë¡œ íƒì§€ ì‹œìŠ¤í…œ ì‚¬ìš©)
          deploymentInfo = await jenkinsService.extractDeploymentInfo(fullProjectName, parseInt(buildNumber));
        }

        const buildStatus = 'SUCCESS';

        // NAS ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸ ë° ê²€ì¦
        if (deploymentInfo.nasPath || deploymentInfo.deploymentPath) {
          const nasPath = deploymentInfo.nasPath || deploymentInfo.deploymentPath;

          // Windows ê²½ë¡œë¥¼ Unix ê²½ë¡œë¡œ ë³€í™˜
          let unixPath = nasPath
            .replace(/\\\\/g, '')              // \\ ì œê±°
            .replace('nas.roboetech.com', '')   // í˜¸ìŠ¤íŠ¸ëª… ì œê±°
            .replace(/\\/g, '/')                // \ -> /
            .replace(/^\/+/, '');               // ì•ì˜ ì¤‘ë³µ ìŠ¬ë˜ì‹œ ì •ë¦¬

          // release_versionì„ Synology APIìš© ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
          if (!unixPath.startsWith('/release_version/')) {
            unixPath = unixPath.replace(/^release_version\//, '/release_version/');
            if (!unixPath.startsWith('/release_version/')) {
              unixPath = '/release_version/' + unixPath;
            }
          }

          logger.info(`Checking NAS directory existence: ${unixPath}`);

          // ì‹¤ì œ NAS ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
          const directoryExists = await nasService.directoryExists(unixPath);

          if (directoryExists) {
            // ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ë©´ íŒŒì¼ ëª©ë¡ë„ ì¡°íšŒ
            try {
              const files = await nasService.getDirectoryFiles(unixPath);
              deploymentInfo.verifiedFiles = files;
              deploymentInfo.directoryVerified = true;

              // NASì—ì„œ í•´ë‹¹ ë²„ì „ ê´€ë ¨ íŒŒì¼ë“¤ ì°¾ê¸°
              const versionFiles = files.filter(file => {
                const isDeploymentFile = file.endsWith('.tar.gz') || file.endsWith('.enc.tar.gz');
                return isDeploymentFile;
              });

              deploymentInfo.allFiles = versionFiles;
              deploymentInfo.verifiedAllFiles = versionFiles;

              logger.info(`Found ${versionFiles.length} deployment files in NAS: ${versionFiles.join(', ')}`);

              // ë©”ì¸ ë‹¤ìš´ë¡œë“œ íŒŒì¼ ì„¤ì • (Vë¡œ ì‹œì‘í•˜ëŠ” ë¹„ì•”í˜¸í™” íŒŒì¼ ìš°ì„ )
              const mainFile = versionFiles.find(f => f.startsWith('V') && !f.includes('.enc.'));
              if (mainFile) {
                deploymentInfo.downloadFile = mainFile;
                deploymentInfo.downloadFileVerified = true;
                logger.info(`Set download file to: ${mainFile}`);
              }

              logger.info(`NAS directory verified: ${unixPath} (${files.length} files found)`);

              // NAS ìŠ¤ìº” ì„±ê³µ ì‹œ ìºì‹œì— ì €ì¥
              try {
                const deploymentPathService = getDeploymentPathService();
                const buildDate = new Date(); // í˜„ì¬ ë‚ ì§œë¥¼ ë¹Œë“œ ë‚ ì§œë¡œ ì‚¬ìš©

                await deploymentPathService.saveDeploymentPath({
                  projectName: fullProjectName,
                  version: version || '1.0.0',
                  buildNumber: parseInt(buildNumber) || 0,
                  buildDate: buildDate,
                  nasPath: deploymentInfo.nasPath || deploymentInfo.deploymentPath,
                  downloadFile: deploymentInfo.downloadFile,
                  allFiles: deploymentInfo.allFiles || [],
                });

                logger.info(`Cached deployment path: ${fullProjectName} v${version} #${buildNumber}`);
              } catch (cacheError) {
                // ìºì‹œ ì €ì¥ ì‹¤íŒ¨í•´ë„ ë©”ì¸ ë¡œì§ì€ ê³„ì† ì§„í–‰
                logger.warn(`Failed to cache deployment path: ${cacheError.message}`);
              }
            } catch (error) {
              logger.warn(`Failed to get file list for ${unixPath}: ${error.message}`);
              deploymentInfo.directoryVerified = true;
              deploymentInfo.verificationWarning = 'Directory exists but file list unavailable';
            }
          }
        }

        // Synology ê³µìœ  ë§í¬ ìƒì„± ì‹œë„ (3-segment route)
        if (deploymentInfo && (deploymentInfo.nasPath || deploymentInfo.deploymentPath)) {
          // í”„ë¡œì íŠ¸ëª…ì—ì„œ ë²„ì „ê³¼ ë‚ ì§œ ì¶”ì¶œ
          const extractedVersion = version; // 3-segment routeëŠ” version íŒŒë¼ë¯¸í„°ê°€ ìˆìŒ
          let date = '250310'; // ê¸°ë³¸ê°’
          let buildNum = buildNumber;

          // í”„ë¡œì íŠ¸ëª… ë° NAS ê²½ë¡œì—ì„œ ë‚ ì§œ/ë¹Œë“œ ë²ˆí˜¸ ì¶”ì¶œ (Windows ê²½ë¡œ ì§€ì›)
          const dateMatch = fullProjectName.match(/_(\d{6})_/) || deploymentInfo.nasPath?.match(/[\\\/](\d{6})[\\\/]/);
          const buildMatch = fullProjectName.match(/_(\d+)$/) || deploymentInfo.nasPath?.match(/[\\\/](\d+)$/);

          if (dateMatch) date = dateMatch[1];
          if (buildMatch) buildNum = buildMatch[1];

          logger.info(`ğŸ” ë‚ ì§œ/ë¹Œë“œë²ˆí˜¸ ì¶”ì¶œ ê²°ê³¼ (3-segment) - date: ${date}, buildNum: ${buildNum}, nasPath: ${deploymentInfo.nasPath}`);

          logger.info(`ğŸ”— Synology API í˜¸ì¶œ ì‹œì‘ (3-segment) - getOrCreateVersionShareLink(${extractedVersion}, ${date}, ${buildNum})`);
          try {
            const shareResult = await Promise.race([
              synologyApiService.getOrCreateVersionShareLink(extractedVersion, date, buildNum),
              new Promise((_, reject) => setTimeout(() => reject(new Error('Synology API timeout')), 3000)),
            ]);

            logger.info('ğŸ”— Synology API ì‘ë‹µ (3-segment):', JSON.stringify(shareResult, null, 2));

            if (shareResult.success) {
              deploymentInfo.synologyShareUrl = shareResult.shareUrl;
              deploymentInfo.synologyShareId = shareResult.shareId;
              deploymentInfo.shareCreated = shareResult.isNew;

              logger.info(`Synology folder share link ${shareResult.isNew ? 'created' : 'found'} (3-segment): ${shareResult.shareUrl}`);
            } else {
              logger.warn(`Synology share link creation failed (3-segment): ${shareResult.error}`);
            }
          } catch (shareError) {
            logger.warn(`Synology share link error (3-segment): ${shareError.message}`);
          }

          // íŒŒì¼ ì •ë³´ ë§¤í•‘ ìƒì„±
          if (deploymentInfo.allFiles && deploymentInfo.allFiles.length > 0) {
            try {
              const fileInfoResult = await synologyApiService.findActualFileNames(
                deploymentInfo.nasPath, extractedVersion, date,
              );
              if (fileInfoResult.success) {
                deploymentInfo.fileInfoMap = fileInfoResult.fileInfoMap || {};
                logger.info('File info map created (3-segment):', JSON.stringify(deploymentInfo.fileInfoMap, null, 2));
              }
            } catch (fileInfoError) {
              logger.warn(`File info mapping failed (3-segment): ${fileInfoError.message}`);
              deploymentInfo.fileInfoMap = {};
            }
          }
        }

        return res.json({
          success: true,
          data: {
            projectName: fullProjectName,
            buildNumber: parseInt(buildNumber),
            status: buildStatus,
            deploymentPath: deploymentInfo.deploymentPath,
            nasPath: deploymentInfo.nasPath,
            downloadFile: deploymentInfo.downloadFile,
            allFiles: deploymentInfo.allFiles || [],
            verifiedFiles: deploymentInfo.verifiedFiles || [],
            directoryVerified: deploymentInfo.directoryVerified || false,
            downloadFileVerified: deploymentInfo.downloadFileVerified || false,
            buildDate: deploymentInfo.buildDate,
            buildNumber: deploymentInfo.buildNumber,
            synologyShareUrl: deploymentInfo.synologyShareUrl,
            synologyShareId: deploymentInfo.synologyShareId,
            shareCreated: deploymentInfo.shareCreated,
            fileInfoMap: deploymentInfo.fileInfoMap || {},
          },
          message: 'ë°°í¬ ì •ë³´ë¥¼ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.',
        });

      } catch (innerError) {
        logger.error(`Jenkins ë°°í¬ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ - ${fullProjectName}#${buildNumber}: ${innerError.message}`);
        logger.error('Inner error stack:', innerError.stack);

        return res.status(404).json({
          success: false,
          error: {
            code: 'NOT_FOUND',
            message: 'ìš”ì²­í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
          },
        });
      }
    } catch (error) {
      logger.error(`ë°°í¬ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: ${error.message}`);
      next(error);
    }
  },
);

// Jenkins ë°°í¬ ì •ë³´ ì¡°íšŒ (NAS ê²½ë¡œ, ë‹¤ìš´ë¡œë“œ íŒŒì¼ ë“±) - 2-segment URL fallback
router.get('/deployment-info/:projectName/:buildNumber',
  [
    param('projectName').isString().withMessage('í”„ë¡œì íŠ¸ëª…ì€ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤'),
    param('buildNumber').isInt({ min: 1 }).withMessage('ë¹Œë“œ ë²ˆí˜¸ëŠ” ì–‘ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤'),
  ],
  async (req, res, next) => {
    try {
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        return res.status(400).json({
          success: false,
          message: 'ì…ë ¥ ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.',
          errors: errors.array(),
        });
      }

      const { projectName, buildNumber } = req.params;

      logger.info(`ë°°í¬ ì •ë³´ ì¡°íšŒ ìš”ì²­ - ì‚¬ìš©ì: ${req.user.username}, í”„ë¡œì íŠ¸: ${projectName}, ë¹Œë“œ: ${buildNumber}`);

      const jenkinsService = getJenkinsService();
      const nasService = getNASService();
      const SynologyApiService = require('../services/synologyApiService');
      const synologyApiService = new SynologyApiService();

      try {
        logger.info(`ë°°í¬ ì •ë³´ ì¡°íšŒ ì‹œì‘ (2-segment) - í”„ë¡œì íŠ¸: ${projectName}, ë¹Œë“œ: ${buildNumber}`);

        // 1. ë¨¼ì € deployment_paths í…Œì´ë¸”ì—ì„œ ê¸°ì¡´ ê²€ì¦ëœ ë°ì´í„° í™•ì¸ (ìµœì í™”ë¨)
        let deploymentInfo = null;
        try {
          logger.info(`DB ì¿¼ë¦¬ ì‹œë„ (2-segment) - í”„ë¡œì íŠ¸: ${projectName}, ë¹Œë“œ: ${buildNumber}`);
          const { query } = require('../config/database');

          const dbResult = await query(
            'SELECT * FROM deployment_paths WHERE project_name = $1 AND build_number = $2',
            [projectName, parseInt(buildNumber)],
          );

          logger.info(`DB ì¿¼ë¦¬ ê²°ê³¼ (2-segment) - í–‰ ê°œìˆ˜: ${dbResult.rows.length}`);

          if (dbResult.rows.length > 0) {
            const dbRecord = dbResult.rows[0];
            logger.info(`DB ë ˆì½”ë“œ ë°œê²¬ (2-segment) - all_files: ${JSON.stringify(dbRecord.all_files)}`);
            deploymentInfo = {
              deploymentPath: dbRecord.nas_path,
              nasPath: dbRecord.nas_path,
              downloadFile: dbRecord.download_file,
              allFiles: dbRecord.all_files || [],
              verifiedFiles: dbRecord.all_files || [],
              directoryVerified: true,
              downloadFileVerified: true,
              buildDate: dbRecord.build_date,
              buildNumber: dbRecord.build_number,
            };
            logger.info(`Found verified deployment data in database (2-segment) for ${projectName}#${buildNumber}`);
            logger.info(`DB allFiles (2-segment): ${JSON.stringify(dbRecord.all_files)}`);
          } else {
            logger.warn(`DBì—ì„œ ë ˆì½”ë“œë¥¼ ì°¾ì§€ ëª»í•¨ (2-segment) - ${projectName}#${buildNumber}`);
          }
        } catch (dbError) {
          logger.error(`Database query failed (2-segment): ${dbError.message}`);
          logger.error(`DB ì—°ê²° ì •ë³´ (2-segment) - host: ${process.env.DB_HOST}, port: ${process.env.DB_PORT}, db: ${process.env.DB_NAME}, user: ${process.env.DB_USER}`);
        }

        // 2. DBì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜ (ì„±ëŠ¥ ìµœì í™”)
        logger.info(`ğŸ” DB ì¡°íšŒ ê²°ê³¼ í™•ì¸ - deploymentInfo exists: ${!!deploymentInfo}`);
        if (deploymentInfo) {
          logger.info('ğŸ“‹ ìºì‹œëœ ë°ì´í„° ë°œê²¬, ì¦‰ì‹œ ë°˜í™˜í•©ë‹ˆë‹¤');

          return res.json({
            success: true,
            data: {
              projectName,
              buildNumber: parseInt(buildNumber),
              status: 'SUCCESS',
              deploymentPath: deploymentInfo.deploymentPath,
              nasPath: deploymentInfo.nasPath,
              downloadFile: deploymentInfo.downloadFile,
              allFiles: deploymentInfo.allFiles || [],
              verifiedFiles: deploymentInfo.verifiedFiles || [],
              directoryVerified: deploymentInfo.directoryVerified || false,
              downloadFileVerified: deploymentInfo.downloadFileVerified || false,
              buildDate: deploymentInfo.buildDate,
              buildNumber: deploymentInfo.buildNumber,
              cached: true, // ìºì‹œëœ ë°ì´í„°ì„ì„ í‘œì‹œ
            },
            message: 'ìºì‹œëœ ë°°í¬ ì •ë³´ë¥¼ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.',
          });
        }

        // 3. DBì— ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ë§Œ ëŠë¦° ì‘ì—… ìˆ˜í–‰
        logger.info(`ìºì‹œëœ ë°ì´í„°ê°€ ì—†ì–´ ì‹¤ì‹œê°„ ì¡°íšŒë¥¼ ì‹œì‘í•©ë‹ˆë‹¤`);
        // ì„±ëŠ¥ìƒì˜ ì´ìœ ë¡œ ì‹¤ì‹œê°„ ì¡°íšŒëŠ” ë¹„í™œì„±í™” (ìºì‹œëœ ë°ì´í„°ë§Œ ì‚¬ìš©)
        return res.json({
          success: false,
          message: 'ìºì‹œëœ ë°°í¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.',
          data: {
            projectName,
            buildNumber: parseInt(buildNumber),
            status: 'NO_CACHE',
            cached: false,
          }
        });

        // ì•„ë˜ëŠ” ì›ë˜ì˜ ëŠë¦° ì½”ë“œ (ë¹„í™œì„±í™”ë¨)
        if (false) {
          logger.info('ğŸ“‹ deploymentInfo ë‚´ìš©:', JSON.stringify(deploymentInfo, null, 2));
          // í”„ë¡œì íŠ¸ëª…ì—ì„œ ë²„ì „ê³¼ ë‚ ì§œ ì¶”ì¶œ (ì˜ˆ: mr4.0.0_release)
          let version = '4.0.0';
          let date = '251013';
          let buildNum = buildNumber;

          // í”„ë¡œì íŠ¸ëª… ë° NAS ê²½ë¡œì—ì„œ ì •ë³´ ì¶”ì¶œ (Windows ê²½ë¡œ ì§€ì›)
          const versionMatch = projectName.match(/mr(\d+\.\d+\.\d+)/) || deploymentInfo.nasPath?.match(/mr(\d+\.\d+\.\d+)/);
          const dateMatch = projectName.match(/_(\d{6})_/) || deploymentInfo.nasPath?.match(/[\\\/](\d{6})[\\\/]/);
          const buildMatch = projectName.match(/_(\d+)$/) || deploymentInfo.nasPath?.match(/[\\\/](\d+)$/);

          if (versionMatch) version = versionMatch[1];
          if (dateMatch) date = dateMatch[1];
          if (buildMatch) buildNum = buildMatch[1];

          logger.info(`ì¶”ì¶œëœ ì •ë³´ (2-segment) - version: ${version}, date: ${date}, buildNum: ${buildNum}, nasPath: ${deploymentInfo.nasPath}`);

          // Synology ê³µìœ  ë§í¬ ìƒì„± ì‹œë„ (ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰, ì˜¤ë¥˜ê°€ ë‚˜ë„ ì‘ë‹µ ì°¨ë‹¨í•˜ì§€ ì•ŠìŒ)
          logger.info(`ğŸ”— Synology API í˜¸ì¶œ ì‹œì‘ - getOrCreateVersionShareLink(${version}, ${date}, ${buildNum})`);
          try {
            const shareResult = await Promise.race([
              synologyApiService.getOrCreateVersionShareLink(version, date, buildNum),
              new Promise((_, reject) => setTimeout(() => reject(new Error('Synology API timeout')), 3000)),
            ]);

            logger.info('ğŸ”— Synology API ì‘ë‹µ:', JSON.stringify(shareResult, null, 2));

            if (shareResult.success) {
              deploymentInfo.synologyShareUrl = shareResult.shareUrl;
              deploymentInfo.synologyShareId = shareResult.shareId;
              deploymentInfo.shareCreated = shareResult.isNew;

              logger.info(`Synology folder share link ${shareResult.isNew ? 'created' : 'found'} (2-segment): ${shareResult.shareUrl}`);
            } else {
              logger.warn(`Synology share link creation failed (2-segment): ${shareResult.error}`);
            }
          } catch (shareError) {
            logger.warn(`Synology share link error (2-segment): ${shareError.message}`);
          }

          return res.json({
            success: true,
            data: {
              projectName,
              buildNumber: parseInt(buildNumber),
              status: 'SUCCESS',
              deploymentPath: deploymentInfo.deploymentPath,
              nasPath: deploymentInfo.nasPath,
              downloadFile: deploymentInfo.downloadFile,
              allFiles: deploymentInfo.allFiles || [],
              verifiedFiles: deploymentInfo.verifiedFiles || [],
              directoryVerified: deploymentInfo.directoryVerified || false,
              downloadFileVerified: deploymentInfo.downloadFileVerified || false,
              buildDate: deploymentInfo.buildDate,
              buildNumber: deploymentInfo.buildNumber,
              synologyShareUrl: deploymentInfo.synologyShareUrl,
              synologyShareId: deploymentInfo.synologyShareId,
              shareCreated: deploymentInfo.shareCreated,
              fileInfoMap: deploymentInfo.fileInfoMap || {},
            },
            message: 'ë°°í¬ ì •ë³´ë¥¼ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.',
          });
        }

        // 3. DBì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ Jenkinsì—ì„œ ë™ì ìœ¼ë¡œ ì¡°íšŒ
        // Jenkinsì—ì„œ ë¹Œë“œ ì •ë³´ í™•ì¸ - extractDeploymentInfoFromBuildLogë¥¼ í†µí•´ ìƒíƒœë„ í™•ì¸
        let buildStatus = null;
        try {
          logger.info(`Jenkins ë¹Œë“œ ë¡œê·¸ ì¶”ì¶œ ì‹œë„ - ${projectName}#${buildNumber}`);
          // ë¹Œë“œ ë¡œê·¸ì—ì„œ ì •ë³´ë¥¼ ë¨¼ì € ì¶”ì¶œí•´ë³´ê³  ìƒíƒœ í™•ì¸
          const preliminaryInfo = await jenkinsService.extractDeploymentInfoFromBuildLog(projectName, parseInt(buildNumber));
          buildStatus = 'SUCCESS'; // ë¡œê·¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìœ¼ë©´ ë¹Œë“œëŠ” ì™„ë£Œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
          logger.info(`Jenkins ë¹Œë“œ ë¡œê·¸ ì¶”ì¶œ ì„±ê³µ - ${projectName}#${buildNumber}`);
        } catch (error) {
          logger.error(`ë¹Œë“œ ë¡œê·¸ ì ‘ê·¼ ì‹¤íŒ¨ - ${projectName}#${buildNumber}: ${error.message}`);
          logger.error('Error stack:', error.stack);
          buildStatus = 'UNKNOWN';
        }

        // ì‹¤íŒ¨í•œ ë°°í¬ì¸ ê²½ìš° íŒŒì¼ ê²€ìƒ‰ ì—†ì´ ê¸°ë³¸ ì •ë³´ë§Œ ë°˜í™˜
        if (buildStatus === 'FAILURE' || buildStatus === 'FAILED' || buildStatus === 'ABORTED') {
          logger.info(`ë°°í¬ ì‹¤íŒ¨ ìƒíƒœ(${buildStatus})ë¡œ ì¸í•´ íŒŒì¼ ê²€ìƒ‰ ìƒëµ - í”„ë¡œì íŠ¸: ${projectName}, ë¹Œë“œ: ${buildNumber}`);

          return res.json({
            success: true,
            data: {
              projectName,
              buildNumber: parseInt(buildNumber),
              status: buildStatus,
              deploymentPath: null,
              nasPath: null,
              downloadFile: null,
              allFiles: [],
              verifiedFiles: [],
              directoryVerified: false,
              downloadFileVerified: false,
              message: `ë°°í¬ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ (${buildStatus}). ì•„í‹°íŒ©íŠ¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.`,
            },
            message: 'ë°°í¬ ì •ë³´ë¥¼ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.',
          });
        }

        // Jenkinsì—ì„œ ë°°í¬ ì •ë³´ ì¡°íšŒ (PRD ê¸°ë°˜ ìë™ ê²½ë¡œ íƒì§€ ì‹œìŠ¤í…œ ì‚¬ìš©)
        deploymentInfo = await jenkinsService.extractDeploymentInfo(projectName, parseInt(buildNumber));

        // NAS ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸ ë° ê²€ì¦
        if (deploymentInfo.nasPath || deploymentInfo.deploymentPath) {
          const nasPath = deploymentInfo.nasPath || deploymentInfo.deploymentPath;

          // Windows ê²½ë¡œë¥¼ Unix ê²½ë¡œë¡œ ë³€í™˜
          let unixPath = nasPath
            .replace(/\\\\/g, '')              // \\ ì œê±°
            .replace('nas.roboetech.com', '')   // í˜¸ìŠ¤íŠ¸ëª… ì œê±°
            .replace(/\\/g, '/')                // \ -> /
            .replace(/^\/+/, '');               // ì•ì˜ ì¤‘ë³µ ìŠ¬ë˜ì‹œ ì •ë¦¬

          // release_versionì„ Synology APIìš© ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
          if (!unixPath.startsWith('/release_version/')) {
            unixPath = unixPath.replace(/^release_version\//, '/release_version/');
            if (!unixPath.startsWith('/release_version/')) {
              unixPath = '/release_version/' + unixPath;
            }
          }

          logger.info(`Checking NAS directory existence: ${unixPath}`);

          // ì‹¤ì œ NAS ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
          const directoryExists = await nasService.directoryExists(unixPath);

          if (directoryExists) {
            // ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ë©´ íŒŒì¼ ëª©ë¡ë„ ì¡°íšŒ
            try {
              const files = await nasService.getDirectoryFiles(unixPath);
              deploymentInfo.verifiedFiles = files;
              deploymentInfo.directoryVerified = true;

              // ë‹¤ìš´ë¡œë“œ íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
              if (deploymentInfo.downloadFile) {
                const fileExists = files.includes(deploymentInfo.downloadFile);
                deploymentInfo.downloadFileVerified = fileExists;

                if (!fileExists) {
                  logger.warn(`Download file ${deploymentInfo.downloadFile} not found in directory ${unixPath}`);
                  logger.info(`Available files in directory: ${files.join(', ')}`);

                  // V{version}_{date} íŒ¨í„´ìœ¼ë¡œ íŒŒì¼ ì°¾ê¸° (ì‹œê°„ ë¬´ê´€)
                  const versionDateMatch = deploymentInfo.downloadFile.match(/V(\d+\.\d+\.\d+)_(\d{6})/);
                  if (versionDateMatch) {
                    const version = versionDateMatch[1];
                    const date = versionDateMatch[2];
                    const pattern = `V${version}_${date}`;

                    logger.info(`Looking for files with pattern: ${pattern}*`);

                    // ê°™ì€ ë²„ì „ê³¼ ë‚ ì§œë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ ì°¾ê¸° (ì‹œê°„ì€ ë¬´ê´€)
                    const alternativeFile = files.find(f =>
                      f.startsWith(pattern) && f.endsWith('.tar.gz') && !f.includes('.enc.'),
                    );

                    if (alternativeFile) {
                      deploymentInfo.downloadFile = alternativeFile;
                      deploymentInfo.downloadFileVerified = true;
                      logger.info(`Found alternative download file with pattern ${pattern}: ${alternativeFile}`);
                    } else {
                      logger.warn(`No files found with pattern ${pattern} in available files`);
                    }
                  }
                }
              }

              // allFiles ë°°ì—´ì˜ íŒŒì¼ë“¤ë„ ê²€ì¦í•˜ê³ , NASì—ì„œ ì‹¤ì œ ë°°í¬ íŒŒì¼ ì°¾ê¸°
              if (deploymentInfo.allFiles && deploymentInfo.allFiles.length > 0) {
                deploymentInfo.verifiedAllFiles = deploymentInfo.allFiles.filter(file => files.includes(file));
                deploymentInfo.allFiles = deploymentInfo.verifiedAllFiles; // ì¡´ì¬í•˜ëŠ” íŒŒì¼ë§Œ ë°˜í™˜
              } else {
                // allFilesê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°, NASì—ì„œ ì§ì ‘ ë°°í¬ íŒŒì¼ ì°¾ê¸°
                deploymentInfo.allFiles = [];

                // ë²„ì „ ì •ë³´ ì¶”ì¶œ
                const versionMatch = projectName.match(/(\d+\.\d+\.\d+)/);
                if (versionMatch) {
                  const version = versionMatch[1];

                  // NASì—ì„œ í•´ë‹¹ ë²„ì „ ê´€ë ¨ íŒŒì¼ë“¤ ì°¾ê¸°
                  const versionFiles = files.filter(file => {
                    const isDeploymentFile = file.endsWith('.tar.gz') || file.endsWith('.enc.tar.gz');
                    const hasVersionInName = file.includes(version);
                    return isDeploymentFile && hasVersionInName;
                  });

                  deploymentInfo.allFiles = versionFiles;
                  deploymentInfo.verifiedAllFiles = versionFiles;

                  logger.info(`Found ${versionFiles.length} version-related files in NAS: ${versionFiles.join(', ')}`);

                  // ë©”ì¸ ë‹¤ìš´ë¡œë“œ íŒŒì¼ë„ ë‹¤ì‹œ ì„¤ì • (V{version}ë¡œ ì‹œì‘í•˜ëŠ” ë¹„ì•”í˜¸í™” íŒŒì¼ ìš°ì„ )
                  if (!deploymentInfo.downloadFileVerified) {
                    const mainFile = versionFiles.find(f => f.startsWith('V') && !f.includes('.enc.'));
                    if (mainFile) {
                      deploymentInfo.downloadFile = mainFile;
                      deploymentInfo.downloadFileVerified = true;
                      logger.info(`Updated download file to: ${mainFile}`);
                    }
                  }
                }
              }

              logger.info(`NAS directory verified: ${unixPath} (${files.length} files found)`);

              // NAS ìŠ¤ìº” ì„±ê³µ ì‹œ ìºì‹œì— ì €ì¥ (2-segment route)
              try {
                const deploymentPathService = getDeploymentPathService();
                const buildDate = new Date(); // í˜„ì¬ ë‚ ì§œë¥¼ ë¹Œë“œ ë‚ ì§œë¡œ ì‚¬ìš©

                // í”„ë¡œì íŠ¸ëª…ì—ì„œ ë²„ì „ ì¶”ì¶œ
                const versionMatch = projectName.match(/(\d+\.\d+\.\d+)/);
                const extractedVersion = versionMatch ? versionMatch[1] : '1.0.0';

                await deploymentPathService.saveDeploymentPath({
                  projectName: projectName,
                  version: extractedVersion,
                  buildNumber: parseInt(buildNumber) || 0,
                  buildDate: buildDate,
                  nasPath: deploymentInfo.nasPath || deploymentInfo.deploymentPath,
                  downloadFile: deploymentInfo.downloadFile,
                  allFiles: deploymentInfo.allFiles || [],
                });

                logger.info(`Cached deployment path (2-segment): ${projectName} v${extractedVersion} #${buildNumber}`);
              } catch (cacheError) {
                // ìºì‹œ ì €ì¥ ì‹¤íŒ¨í•´ë„ ë©”ì¸ ë¡œì§ì€ ê³„ì† ì§„í–‰
                logger.warn(`Failed to cache deployment path (2-segment): ${cacheError.message}`);
              }
            } catch (error) {
              logger.warn(`Failed to get file list for ${unixPath}: ${error.message}`);
              deploymentInfo.directoryVerified = true;
              deploymentInfo.verificationWarning = 'Directory exists but file list unavailable';
            }
          } else {
            deploymentInfo.directoryVerified = false;
            deploymentInfo.downloadFileVerified = false;

            // ëŒ€ì²´ ê²½ë¡œë“¤ ì‹œë„
            const versionMatch = projectName.match(/(\d+\.\d+\.\d+)/);
            if (versionMatch) {
              const version = versionMatch[1];
              const alternativePaths = [
                `release_version/release/product/mr${version}`,
                `release_version/release/product/${version}`,
                `release_version/${version}`,
                `release_version/projects/${version}`,
              ];

              logger.info(`Original path ${unixPath} not found, trying alternatives...`);

              for (const altPath of alternativePaths) {
                const exists = await nasService.directoryExists(altPath);
                if (exists) {
                  try {
                    const files = await nasService.getDirectoryFiles(altPath);
                    deploymentInfo.nasPath = `\\\\nas.roboetech.com\\${altPath.replace(/\//g, '\\')}`;
                    deploymentInfo.deploymentPath = deploymentInfo.nasPath;
                    deploymentInfo.directoryVerified = true;
                    deploymentInfo.verifiedFiles = files;
                    deploymentInfo.alternativePathUsed = altPath;

                    logger.info(`Found alternative NAS path: ${altPath} (${files.length} files)`);

                    // ëŒ€ì²´ ê²½ë¡œ ì°¾ì€ ê²½ìš°ì—ë„ ìºì‹œì— ì €ì¥
                    try {
                      const deploymentPathService = getDeploymentPathService();
                      const buildDate = new Date(); // í˜„ì¬ ë‚ ì§œë¥¼ ë¹Œë“œ ë‚ ì§œë¡œ ì‚¬ìš©

                      await deploymentPathService.saveDeploymentPath({
                        projectName: projectName,
                        version: version,
                        buildNumber: parseInt(buildNumber) || 0,
                        buildDate: buildDate,
                        nasPath: deploymentInfo.nasPath,
                        downloadFile: deploymentInfo.downloadFile,
                        allFiles: files || [],
                      });

                      logger.info(`Cached alternative deployment path: ${projectName} v${version} #${buildNumber} -> ${altPath}`);
                    } catch (cacheError) {
                      // ìºì‹œ ì €ì¥ ì‹¤íŒ¨í•´ë„ ë©”ì¸ ë¡œì§ì€ ê³„ì† ì§„í–‰
                      logger.warn(`Failed to cache alternative deployment path: ${cacheError.message}`);
                    }
                    break;
                  } catch (error) {
                    logger.warn(`Failed to get files from alternative path ${altPath}: ${error.message}`);
                  }
                }
              }
            }

            if (!deploymentInfo.directoryVerified) {
              logger.warn(`No valid NAS directory found for deployment ${projectName}#${buildNumber}`);
              deploymentInfo.verificationError = 'NAS directory not found';
            }
          }
        } else {
          deploymentInfo.directoryVerified = false;
          deploymentInfo.verificationError = 'No NAS path found in deployment info';
          logger.warn(`No NAS path found for deployment ${projectName}#${buildNumber}`);
        }

        // ì‹œë†€ë¡œì§€ ê³µìœ  ë§í¬ ë° íŒŒì¼ë³„ ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„± (ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ)
        if (deploymentInfo.directoryVerified && deploymentInfo.nasPath) {
          try {
            // NAS ê²½ë¡œì—ì„œ ë²„ì „, ë‚ ì§œ, ë¹Œë“œ ë²ˆí˜¸ ì¶”ì¶œ (Windows ë° Unix ê²½ë¡œ ëª¨ë‘ ì§€ì›)
            logger.info(`Trying to extract version info from NAS path: ${deploymentInfo.nasPath}`);
            const pathMatch = deploymentInfo.nasPath.match(/mr(\d+\.\d+\.\d+)[\\\/](\d+)[\\\/](\d+)/);
            if (pathMatch) {
              const [, version, date, buildNum] = pathMatch;

              logger.info(`Creating Synology links for version ${version}, date ${date}, build ${buildNum}`);

              // 0. ì‹¤ì œ íŒŒì¼ëª… ì°¾ê¸°
              const folderPath = `/release_version/release/product/mr${version}/${date}/${buildNum}`;
              const actualFileNamesResult = await Promise.race([
                synologyApiService.findActualFileNames(folderPath, version, date),
                new Promise((_, reject) => setTimeout(() => reject(new Error('File listing timeout')), 3000)),
              ]);

              let actualFileNames = {};
              let fileInfoMap = {};
              if (actualFileNamesResult.success) {
                actualFileNames = actualFileNamesResult.fileMap;
                fileInfoMap = actualFileNamesResult.fileInfoMap || {};
                logger.info(`Found actual file names: ${JSON.stringify(actualFileNames)}`);
                logger.info(`Found file info: ${JSON.stringify(fileInfoMap)}`);

                // ì‹¤ì œ íŒŒì¼ëª…ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                if (actualFileNames.main) {
                  deploymentInfo.downloadFile = actualFileNames.main;
                  deploymentInfo.downloadFileVerified = true;
                }

                // ì¶”ê°€ íŒŒì¼ ì •ë³´ ì—…ë°ì´íŠ¸
                deploymentInfo.actualFiles = {
                  main: actualFileNames.main || null,
                  morow: actualFileNames.morow || null,
                  backend: actualFileNames.backend || null,
                  frontend: actualFileNames.frontend || null,
                };

                // íŒŒì¼ ì •ë³´ ì¶”ê°€ (í¬ê¸°, ìˆ˜ì •ì¼)
                deploymentInfo.fileInfoMap = fileInfoMap;

                // allFiles ë°°ì—´ì„ ì‹¤ì œ íŒŒì¼ëª…ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                deploymentInfo.allFiles = Object.values(deploymentInfo.actualFiles).filter(file => file !== null);
                logger.info(`Updated allFiles with actual file names: ${JSON.stringify(deploymentInfo.allFiles)}`);
              } else {
                logger.warn(`Failed to find actual file names: ${actualFileNamesResult.error}`);
              }

              // 1. í´ë” ê³µìœ  ë§í¬ ìƒì„± (ê¸°ì¡´)
              const shareResult = await Promise.race([
                synologyApiService.getOrCreateVersionShareLink(version, date, buildNum),
                new Promise((_, reject) => setTimeout(() => reject(new Error('Synology API timeout')), 3000)),
              ]);

              if (shareResult.success) {
                deploymentInfo.synologyShareUrl = shareResult.shareUrl;
                deploymentInfo.synologyShareId = shareResult.shareId;
                deploymentInfo.shareCreated = shareResult.isNew;

                logger.info(`Synology folder share link ${shareResult.isNew ? 'created' : 'found'}: ${shareResult.shareUrl}`);
              } else {
                logger.warn(`Failed to create Synology folder share link: ${shareResult.error}`);
                deploymentInfo.synologyShareError = shareResult.error;
              }

              // 2. ê°œë³„ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„± (ìƒˆë¡œìš´ ê¸°ëŠ¥)
              deploymentInfo.fileDownloadLinks = {};

              // ë©”ì¸ ë‹¤ìš´ë¡œë“œ íŒŒì¼ì— ëŒ€í•œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ ë§í¬
              if (deploymentInfo.downloadFile && deploymentInfo.downloadFileVerified) {
                try {
                  const fileDownloadResult = await Promise.race([
                    synologyApiService.getOrCreateFileDownloadLink(version, date, buildNum, deploymentInfo.downloadFile),
                    new Promise((_, reject) => setTimeout(() => reject(new Error('File download link timeout')), 3000)),
                  ]);

                  if (fileDownloadResult.success) {
                    deploymentInfo.fileDownloadLinks[deploymentInfo.downloadFile] = {
                      downloadUrl: fileDownloadResult.downloadUrl || fileDownloadResult.shareUrl,
                      isDirectDownload: fileDownloadResult.isDirectDownload,
                      fileName: fileDownloadResult.fileName,
                    };

                    // ë©”ì¸ íŒŒì¼ì˜ ë‹¤ìš´ë¡œë“œ ë§í¬ë¥¼ ë³„ë„ë¡œ ì €ì¥
                    deploymentInfo.mainFileDownloadUrl = fileDownloadResult.downloadUrl || fileDownloadResult.shareUrl;
                    deploymentInfo.isMainFileDirectDownload = fileDownloadResult.isDirectDownload;

                    logger.info(`Main file download link created: ${deploymentInfo.mainFileDownloadUrl} (direct: ${fileDownloadResult.isDirectDownload})`);
                  }
                } catch (error) {
                  logger.warn(`Failed to create download link for main file ${deploymentInfo.downloadFile}: ${error.message}`);
                }
              }

              // 3. ì‹¤ì œ íŒŒì¼ë“¤ì— ëŒ€í•œ ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„± (actualFiles ì‚¬ìš©)
              if (deploymentInfo.actualFiles) {
                const fileTypes = ['morow', 'backend', 'frontend'];

                for (const fileType of fileTypes) {
                  const fileName = deploymentInfo.actualFiles[fileType];
                  if (fileName) {
                    try {
                      const fileDownloadResult = await Promise.race([
                        synologyApiService.getOrCreateFileDownloadLink(version, date, buildNum, fileName),
                        new Promise((_, reject) => setTimeout(() => reject(new Error('File download link timeout')), 5000)),
                      ]);

                      if (fileDownloadResult.success) {
                        deploymentInfo.fileDownloadLinks[fileName] = {
                          downloadUrl: fileDownloadResult.downloadUrl || fileDownloadResult.shareUrl,
                          isDirectDownload: fileDownloadResult.isDirectDownload,
                          fileName: fileDownloadResult.fileName,
                          fileType: fileType,
                        };

                        // íŒŒì¼ íƒ€ì…ë³„ë¡œë„ ì €ì¥ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‰½ê²Œ ì ‘ê·¼í•˜ê¸° ìœ„í•´)
                        deploymentInfo.fileDownloadLinks[`${fileType}File`] = deploymentInfo.fileDownloadLinks[fileName];

                        logger.info(`${fileType} file download link created for ${fileName}: ${fileDownloadResult.downloadUrl || fileDownloadResult.shareUrl} (direct: ${fileDownloadResult.isDirectDownload})`);
                      }
                    } catch (error) {
                      logger.warn(`Failed to create download link for ${fileType} file ${fileName}: ${error.message}`);
                      // ê°œë³„ íŒŒì¼ ë§í¬ ìƒì„± ì‹¤íŒ¨ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                    }
                  }
                }
              }

            } else {
              logger.warn(`Could not extract version info from NAS path: ${deploymentInfo.nasPath}`);
            }
          } catch (error) {
            logger.error(`Synology link creation failed (will continue without it): ${error.message}`);
            deploymentInfo.synologyShareError = error.message;
            // ì‹œë†€ë¡œì§€ API ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
          }
        }

        logger.info(`Jenkins ë°°í¬ ì •ë³´ ì¡°íšŒ ì™„ë£Œ - ì‚¬ìš©ì: ${req.user.username}, í”„ë¡œì íŠ¸: ${projectName}, ë¹Œë“œ: ${buildNumber}, ë””ë ‰í† ë¦¬ ê²€ì¦: ${deploymentInfo.directoryVerified}`);

        // ìµœì¢… ì‘ë‹µ ë°ì´í„° ë¡œê¹… (fileInfoMap í¬í•¨)
        logger.info('Final deploymentInfo response data:', JSON.stringify({
          fileInfoMap: deploymentInfo.fileInfoMap,
          actualFiles: deploymentInfo.actualFiles,
          allFiles: deploymentInfo.allFiles,
        }, null, 2));

        res.json({
          success: true,
          data: deploymentInfo,
          message: 'ë°°í¬ ì •ë³´ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.',
        });
      } catch (error) {
        logger.error(`Jenkins ë°°í¬ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ - í”„ë¡œì íŠ¸: ${projectName}, ë¹Œë“œ: ${buildNumber}:`, error.message);
        logger.error('Error stack:', error.stack);

        res.status(500).json({
          success: false,
          message: 'ë°°í¬ ì •ë³´ ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
          error: error.message,
          projectName: projectName,
          buildNumber: buildNumber,
        });
      }
    } catch (error) {
      next(error);
    }
  },
);

// Upload í´ë” ê³µìœ  ë§í¬ ê°€ì ¸ì˜¤ê¸°
router.get('/share/upload',
  authenticateToken,
  async (req, res) => {
    try {
      logger.info(`Upload í´ë” ê³µìœ  ë§í¬ ìš”ì²­ - ì‚¬ìš©ì: ${req.user.username}`);

      const nasService = getNASService();

      // ì—¬ëŸ¬ ê°€ëŠ¥í•œ ì—…ë¡œë“œ ê²½ë¡œ ì‹œë„
      const possibleUploadPaths = [
        '/release_version/release/upload',  // í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ê²½ë¡œ
        '/release_version/upload',          // ë” ìƒìœ„ ê²½ë¡œ
        '/volume1/release_version/release/upload',  // volume1 í¬í•¨
        '/volume1/release_version/upload'   // volume1 í¬í•¨ ìƒìœ„ ê²½ë¡œ
      ];

      let uploadPath = null;
      let pathExists = null;

      // ì¡´ì¬í•˜ëŠ” ê²½ë¡œ ì°¾ê¸°
      for (const testPath of possibleUploadPaths) {
        logger.info(`ì—…ë¡œë“œ ê²½ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘: ${testPath}`);
        pathExists = await nasService.synologyApiService.checkPathExists(testPath);
        logger.info(`ê²½ë¡œ ${testPath} ì¡´ì¬ ì—¬ë¶€: ${JSON.stringify(pathExists)}`);
        
        if (pathExists.success && pathExists.exists) {
          uploadPath = testPath;
          logger.info(`ìœ íš¨í•œ ì—…ë¡œë“œ ê²½ë¡œ ë°œê²¬: ${uploadPath}`);
          break;
        }
      }

      if (!uploadPath) {
        logger.error('ëª¨ë“  ì—…ë¡œë“œ ê²½ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨, ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©');
        uploadPath = '/release_version/release/upload';
      }

      try {
        // upload í´ë”ì— ëŒ€í•´ì„œëŠ” ì§ì ‘ ê²½ë¡œë¡œ ê³µìœ  ë§í¬ ìƒì„±
        const directShareResult = await nasService.synologyApiService.createShareLink(uploadPath);

        if (directShareResult.success && directShareResult.shareUrl) {
          logger.info(`Upload í´ë” ì§ì ‘ ê³µìœ  ë§í¬ ìƒì„± ì„±ê³µ: ${directShareResult.shareUrl}`);

          res.json({
            success: true,
            shareUrl: directShareResult.shareUrl,
            shareId: directShareResult.shareId,
            path: uploadPath,
            method: 'direct',
            message: 'Upload í´ë” ê³µìœ  ë§í¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.',
          });
        } else {
          throw new Error(directShareResult.error || 'Upload í´ë” ê³µìœ  ë§í¬ ìƒì„± ì‹¤íŒ¨');
        }
      } catch (directError) {
        logger.error(`Upload í´ë” ê³µìœ  ë§í¬ ìƒì„± ì‹¤íŒ¨: ${directError.message}`);
        throw new Error(`ê³µìœ  ë§í¬ ìƒì„± ì‹¤íŒ¨: ${directError.message}`);
      }

    } catch (error) {
      logger.error('Upload í´ë” ê³µìœ  ë§í¬ ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨:', error.message);

      res.status(500).json({
        success: false,
        message: 'Upload í´ë” ê³µìœ  ë§í¬ ê°€ì ¸ì˜¤ê¸°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
        error: error.message,
      });
    }
  },
);

/**
 * @swagger
 * /api/deployments/cache/stats:
 *   get:
 *     tags:
 *       - Deployments
 *     summary: ë°°í¬ ê²½ë¡œ ìºì‹œ í†µê³„ ì¡°íšŒ
 *     description: ìºì‹œëœ ë°°í¬ ê²½ë¡œ í†µê³„ ì •ë³´ ì¡°íšŒ
 *     security:
 *       - bearerAuth: []
 *     responses:
 *       200:
 *         description: ìºì‹œ í†µê³„ ì¡°íšŒ ì„±ê³µ
 */
router.get('/cache/stats', async (req, res, next) => {
  try {
    const deploymentPathService = getDeploymentPathService();
    const stats = await deploymentPathService.getCacheStats();

    res.json({
      success: true,
      data: stats,
    });
  } catch (error) {
    next(error);
  }
});

/**
 * @swagger
 * /api/deployments/cache/cleanup:
 *   post:
 *     tags:
 *       - Deployments
 *     summary: ì˜¤ë˜ëœ ìºì‹œ ë°ì´í„° ì •ë¦¬
 *     description: ì§€ì •ëœ ì¼ìˆ˜ë³´ë‹¤ ì˜¤ë˜ëœ ìºì‹œ ë°ì´í„° ì‚­ì œ
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             properties:
 *               daysOld:
 *                 type: integer
 *                 minimum: 1
 *                 maximum: 365
 *                 default: 90
 *                 description: ì‚­ì œí•  ë°ì´í„°ì˜ ê¸°ì¤€ ì¼ìˆ˜
 *     responses:
 *       200:
 *         description: ìºì‹œ ì •ë¦¬ ì„±ê³µ
 */
router.post('/cache/cleanup',
  [
    body('daysOld')
      .optional()
      .isInt({ min: 1, max: 365 })
      .withMessage('daysOld must be between 1 and 365'),
  ],
  async (req, res, next) => {
    try {
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        throw new AppError('ìœ íš¨í•˜ì§€ ì•Šì€ ìš”ì²­ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.', 400, errors.array());
      }

      const { daysOld = 90 } = req.body;
      const deploymentPathService = getDeploymentPathService();

      const deletedCount = await deploymentPathService.cleanupOldPaths(daysOld);

      res.json({
        success: true,
        data: {
          deletedCount,
          daysOld,
          message: `${deletedCount}ê°œì˜ ì˜¤ë˜ëœ ìºì‹œ í•­ëª©ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.`,
        },
      });
    } catch (error) {
      next(error);
    }
  },
);

/**
 * @swagger
 * /api/deployments/cache/invalidate:
 *   delete:
 *     tags:
 *       - Deployments
 *     summary: íŠ¹ì • ë°°í¬ ê²½ë¡œ ìºì‹œ ë¬´íš¨í™”
 *     description: íŠ¹ì • í”„ë¡œì íŠ¸ì˜ ë°°í¬ ê²½ë¡œ ìºì‹œë¥¼ ì‚­ì œ
 *     security:
 *       - bearerAuth: []
 *     parameters:
 *       - in: query
 *         name: projectName
 *         required: true
 *         schema:
 *           type: string
 *         description: í”„ë¡œì íŠ¸ëª…
 *       - in: query
 *         name: version
 *         required: true
 *         schema:
 *           type: string
 *         description: ë²„ì „
 *       - in: query
 *         name: buildNumber
 *         required: true
 *         schema:
 *           type: integer
 *         description: ë¹Œë“œ ë²ˆí˜¸
 *     responses:
 *       200:
 *         description: ìºì‹œ ë¬´íš¨í™” ì„±ê³µ
 */
router.delete('/cache/invalidate',
  [
    query('projectName')
      .notEmpty()
      .withMessage('projectName is required'),
    query('version')
      .notEmpty()
      .withMessage('version is required'),
    query('buildNumber')
      .isInt({ min: 0 })
      .withMessage('buildNumber must be a non-negative integer'),
  ],
  async (req, res, next) => {
    try {
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        throw new AppError('ìœ íš¨í•˜ì§€ ì•Šì€ ìš”ì²­ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.', 400, errors.array());
      }

      const { projectName, version, buildNumber } = req.query;
      const deploymentPathService = getDeploymentPathService();

      const deleted = await deploymentPathService.deleteDeploymentPath(
        projectName,
        version,
        parseInt(buildNumber),
      );

      res.json({
        success: true,
        data: {
          deleted,
          projectName,
          version,
          buildNumber,
          message: deleted ?
            'ìºì‹œê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.' :
            'ì‚­ì œí•  ìºì‹œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        },
      });
    } catch (error) {
      next(error);
    }
  },
);

/**
 * @swagger
 * /api/deployments/{version}/{buildNumber}/artifacts:
 *   get:
 *     tags:
 *       - Deployments
 *     summary: íŠ¹ì • ë°°í¬ì˜ ì•„í‹°íŒ©íŠ¸ ì •ë³´ ì¡°íšŒ
 *     description: ì§€ì—° ë¡œë”©ì„ ìœ„í•œ ê°œë³„ ë°°í¬ì˜ ì•„í‹°íŒ©íŠ¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
 *     security:
 *       - bearerAuth: []
 *     parameters:
 *       - name: version
 *         in: path
 *         required: true
 *         schema:
 *           type: string
 *         description: ë°°í¬ ë²„ì „
 *       - name: buildNumber
 *         in: path
 *         required: true
 *         schema:
 *           type: integer
 *         description: ë¹Œë“œ ë²ˆí˜¸
 *     responses:
 *       200:
 *         description: ì•„í‹°íŒ©íŠ¸ ì •ë³´ ì¡°íšŒ ì„±ê³µ
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 success:
 *                   type: boolean
 *                 data:
 *                   type: object
 *                   properties:
 *                     artifacts:
 *                       type: array
 *                       items:
 *                         type: object
 *                     buildNumber:
 *                       type: integer
 *                     version:
 *                       type: string
 *                     cached:
 *                       type: boolean
 *       404:
 *         description: ë°°í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ
 *       500:
 *         description: ì„œë²„ ì˜¤ë¥˜
 */
router.get(
  '/:version/:buildNumber/artifacts',
  async (req, res, next) => {
    try {
      const { version, buildNumber } = req.params;
      const nasService = getNASService();

      logger.info(`ì•„í‹°íŒ©íŠ¸ ì¡°íšŒ ìš”ì²­ - ì‚¬ìš©ì: ${req.user.username}, ë²„ì „: ${version}, ë¹Œë“œ: ${buildNumber}`);

      // NASì—ì„œ í•´ë‹¹ ë²„ì „ì˜ ì•„í‹°íŒ©íŠ¸ ê²€ìƒ‰
      const artifacts = await nasService.searchFinalArtifactsByVersion(version);

      res.json({
        success: true,
        data: {
          artifacts: artifacts || [],
          buildNumber: parseInt(buildNumber),
          version: version,
          cached: false, // ì‹¤ì‹œê°„ ì¡°íšŒì´ë¯€ë¡œ ìºì‹œë˜ì§€ ì•ŠìŒ
          timestamp: new Date().toISOString(),
        },
      });

      logger.info(`ì•„í‹°íŒ©íŠ¸ ì¡°íšŒ ì™„ë£Œ - ë²„ì „: ${version}, ë¹Œë“œ: ${buildNumber}, ì•„í‹°íŒ©íŠ¸ ìˆ˜: ${artifacts?.length || 0}`);

    } catch (error) {
      logger.error(`ì•„í‹°íŒ©íŠ¸ ì¡°íšŒ ì‹¤íŒ¨ - ë²„ì „: ${req.params.version}, ë¹Œë“œ: ${req.params.buildNumber}, ì˜¤ë¥˜: ${error.message}`);
      next(error);
    }
  },
);

module.exports = router;
