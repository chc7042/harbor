const path = require('path');
const logger = require('../config/logger');
const { AppError } = require('../middleware/error');
const { getCacheService } = require('./cacheService');

/**
 * NAS ì—°ê²° ë° íŒŒì¼ ì‹œìŠ¤í…œ ì ‘ê·¼ ì„œë¹„ìŠ¤ (Synology API ê¸°ë°˜)
 */
class NASService {
  constructor() {
    const SynologyApiService = require('./synologyApiService');
    this.synologyApiService = new SynologyApiService();
    this.releaseBasePath = process.env.NAS_RELEASE_PATH || 'release_version';
    this.cacheService = getCacheService();
  }

  /**
   * NAS ì„œë²„ì— ì—°ê²° (Synology API ì‚¬ìš©)
   */
  async connect() {
    try {
      logger.info('ğŸ” [NAS-CONNECTION] Attempting Synology API login...');
      
      if (!this.synologyApiService) {
        throw new AppError('Synology API service not initialized', 500);
      }
      
      const loginResult = await this.synologyApiService.login();
      logger.info(`ğŸ” [NAS-CONNECTION] Login result: ${JSON.stringify(loginResult)}`);
      logger.info('ğŸ” [NAS-CONNECTION] Synology API login successful');
      return true;
    } catch (error) {
      logger.error(`ğŸ” [NAS-CONNECTION] Failed to connect to NAS via Synology API: ${error.message}`);
      
      // Network-related errors
      if (error.code === 'ECONNREFUSED' || error.code === 'ENOTFOUND' || error.code === 'ETIMEDOUT') {
        throw new AppError(`NAS server unreachable: ${error.message}`, 503);
      }
      
      // Authentication errors
      if (error.message.includes('login failed') || error.message.includes('401') || error.message.includes('403')) {
        throw new AppError(`NAS authentication failed: ${error.message}`, 401);
      }
      
      // Timeout errors
      if (error.code === 'ECONNRESET' || error.message.includes('timeout')) {
        throw new AppError(`NAS connection timeout: ${error.message}`, 504);
      }
      
      // Generic connection error
      throw new AppError(`NAS connection failed: ${error.message}`, 503);
    }
  }

  /**
   * NAS ì—°ê²° í•´ì œ
   */
  async disconnect() {
    try {
      if (!this.synologyApiService) {
        logger.warn('ğŸ” [NAS-DISCONNECT] Synology API service not initialized');
        return;
      }
      
      await this.synologyApiService.logout();
      logger.info('ğŸ” [NAS-DISCONNECT] NAS connection closed successfully');
    } catch (error) {
      logger.error('ğŸ” [NAS-DISCONNECT] Error closing NAS connection:', error.message);
      // Don't throw error on disconnect - log and continue
    }
  }

  /**
   * ë””ë ‰í† ë¦¬ ëª©ë¡ ì¡°íšŒ (ìºì‹œ ì§€ì›)
   */
  async listDirectory(dirPath = '') {
    try {
      if (!this.synologyApiService) {
        throw new AppError('Synology API service not initialized', 500);
      }
      
      // Validate directory path
      if (typeof dirPath !== 'string') {
        throw new AppError('Directory path must be a string', 400);
      }
      
      // ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
      return await this.cacheService.getNASFiles(dirPath, async () => {
        const result = await this.synologyApiService.listDirectoryFiles(dirPath);
        
        if (!result) {
          throw new AppError('No response from NAS service', 500);
        }
        
        if (result.success) {
          if (!Array.isArray(result.files)) {
            logger.warn('NAS API returned non-array files:', result.files);
            return [];
          }
          return result.files;
        } else {
          throw new AppError(`NAS API error: ${result.error || 'Unknown error'}`, 500);
        }
      });
    } catch (error) {
      if (error instanceof AppError) {
        throw error;
      }
      
      logger.error(`ğŸ” [LIST-DIRECTORY] Failed to list directory ${dirPath}:`, error.message);
      
      // Handle specific error types
      if (error.code === 'ECONNREFUSED' || error.code === 'ENOTFOUND') {
        throw new AppError(`NAS server unreachable while listing ${dirPath}`, 503);
      }
      if (error.code === 'ETIMEDOUT') {
        throw new AppError(`Timeout while listing directory ${dirPath}`, 504);
      }
      
      throw new AppError(`Directory listing failed: ${error.message}`, 500);
    }
  }

  /**
   * ë””ë ‰í† ë¦¬ íŒŒì¼ ëª©ë¡ ì¡°íšŒ (ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì„œë“œ)
   */
  async getDirectoryFiles(dirPath = '') {
    return this.listDirectory(dirPath);
  }

  /**
   * íŒŒì¼ ì •ë³´ ì¡°íšŒ
   */
  async getFileInfo(filePath) {
    try {
      if (!this.synologyApiService) {
        throw new AppError('Synology API service not initialized', 500);
      }
      
      // Validate file path
      if (!filePath || typeof filePath !== 'string') {
        throw new AppError('File path is required and must be a string', 400);
      }
      
      const result = await this.synologyApiService.getFileInfo(filePath);
      
      if (!result) {
        throw new AppError('No response from NAS service', 500);
      }
      
      if (result.success && result.data) {
        const fileData = result.data;
        
        // Validate file data structure
        if (!fileData || typeof fileData !== 'object') {
          throw new AppError('Invalid file data structure', 500);
        }
        
        return {
          name: fileData.name || path.basename(filePath),
          path: filePath,
          isDirectory: Boolean(fileData.isdir),
          isFile: !Boolean(fileData.isdir),
          size: parseInt(fileData.size) || 0,
          created: fileData.crtime ? new Date(fileData.crtime * 1000) : new Date(),
          modified: fileData.mtime ? new Date(fileData.mtime * 1000) : new Date(),
          accessed: fileData.atime ? new Date(fileData.atime * 1000) : new Date(),
        };
      } else {
        const errorMsg = result.error || 'File not found';
        logger.warn(`ğŸ” [FILE-INFO] Failed to get info for ${filePath}: ${errorMsg}`);
        
        // Handle specific error cases
        if (errorMsg.includes('not found') || errorMsg.includes('408')) {
          throw new AppError(`File not found: ${filePath}`, 404);
        }
        if (errorMsg.includes('permission') || errorMsg.includes('403')) {
          throw new AppError(`Access denied to file: ${filePath}`, 403);
        }
        
        throw new AppError(`File info failed: ${errorMsg}`, 500);
      }
    } catch (error) {
      if (error instanceof AppError) {
        throw error;
      }
      
      logger.error(`ğŸ” [FILE-INFO] Failed to get file info ${filePath}:`, error.message);
      
      // Handle specific error types
      if (error.code === 'ECONNREFUSED' || error.code === 'ENOTFOUND') {
        throw new AppError(`NAS server unreachable while getting file info for ${filePath}`, 503);
      }
      if (error.code === 'ETIMEDOUT') {
        throw new AppError(`Timeout while getting file info for ${filePath}`, 504);
      }
      
      throw new AppError(`File info failed: ${error.message}`, 500);
    }
  }

  /**
   * íŒŒì¼ ê²€ìƒ‰
   */
  async searchFiles(searchPath, pattern) {
    try {
      const files = await this.listDirectory(searchPath);
      const matchedFiles = [];

      for (const fileName of files) {
        if (pattern && !fileName.toLowerCase().includes(pattern.toLowerCase())) {
          continue;
        }

        try {
          const filePath = path.posix.join(searchPath, fileName);
          const fileInfo = await this.getFileInfo(filePath);

          if (fileInfo.isFile) {
            matchedFiles.push({
              name: fileName,
              path: filePath,
              size: fileInfo.size,
              modified: fileInfo.modified,
              buildNumber: this.extractBuildNumber(fileName),
            });
          }
        } catch (error) {
          logger.warn(`Failed to process search file ${fileName}:`, error.message);
        }
      }

      return matchedFiles.sort((a, b) => new Date(b.modified) - new Date(a.modified));
    } catch (error) {
      logger.error(`Failed to search files in ${searchPath}:`, error.message);
      throw error;
    }
  }

  /**
   * íŒŒì¼ëª…ì—ì„œ ë¹Œë“œ ë²ˆí˜¸ ì¶”ì¶œ
   */
  extractBuildNumber(fileName) {
    const patterns = [
      /build[-_]?(\d+)/i,
      /v(\d+\.\d+\.\d+)/i,
      /version[-_]?(\d+)/i,
      /(\d+)\.tar\.gz$/i,
      /(\d+)\.zip$/i,
    ];

    for (const pattern of patterns) {
      const match = fileName.match(pattern);
      if (match) {
        return match[1];
      }
    }

    return null;
  }

  /**
   * íŒŒì¼ ë‹¤ìš´ë¡œë“œ
   */
  async downloadFile(filePath) {
    logger.info(`NAS downloadFile ìš”ì²­ - íŒŒì¼ ê²½ë¡œ: ${filePath}`);

    try {
      const result = await this.synologyApiService.downloadFile(filePath);
      if (result.success && result.data) {
        logger.info(`File downloaded successfully via Synology API: ${filePath}`);
        return result.data;
      } else {
        throw new Error(result.error || 'Download failed');
      }
    } catch (error) {
      logger.error(`Failed to download file ${filePath}:`, error.message);
      throw new AppError(`File download failed: ${error.message}`, 404);
    }
  }

  /**
   * íŒŒì¼ ëª©ë¡ ì¡°íšŒ (files APIìš©)
   */
  async listFiles(dirPath = '') {
    const fullPath = this.releaseBasePath ? path.posix.join(this.releaseBasePath, dirPath) : dirPath;

    try {
      const result = await this.synologyApiService.listDirectoryFiles(fullPath);
      if (result.success && result.data && result.data.files) {
        return result.data.files.map(file => ({
          name: file.name,
          path: path.posix.join(fullPath, file.name),
          isDirectory: file.isdir,
          isFile: !file.isdir,
          size: file.size || 0,
          modified: new Date(file.mtime * 1000),
        }));
      } else {
        throw new Error(result.error || 'Failed to list files');
      }
    } catch (error) {
      logger.error(`Failed to list files in ${fullPath}:`, error.message);
      throw new AppError(`Directory listing failed: ${error.message}`, 404);
    }
  }

  /**
   * ì—°ê²° ìƒíƒœ í™•ì¸ ë° ì¬ì—°ê²°
   */
  async ensureConnection() {
    try {
      await this.connect();
    } catch (error) {
      logger.error('ğŸ” [ENSURE-CONNECTION] Failed to ensure NAS connection:', error.message);
      throw error; // Re-throw to maintain error context
    }
  }

  /**
   * ì—°ê²° ìƒíƒœ ì¡°íšŒ
   */
  getConnectionStatus() {
    return {
      isConnected: true,
      type: 'Synology API',
      config: {
        baseUrl: process.env.SYNOLOGY_BASE_URL,
        releaseBasePath: this.releaseBasePath,
      },
    };
  }

  /**
   * ë²„ì „ë³„ NAS ì•„í‹°íŒ©íŠ¸ ê²€ìƒ‰ - ì¤‘ì•™í™”ëœ PathResolver ì‚¬ìš©
   */
  async searchArtifactsByVersion(version, pattern = null, jenkinsInfo = null) {
    try {
      await this.ensureConnection();

      // ì¤‘ì•™í™”ëœ ê²½ë¡œ í•´ê²° ì„œë¹„ìŠ¤ ì‚¬ìš©
      const { getPathResolver } = require('./pathResolver');
      const pathResolver = getPathResolver();

      logger.info(`ğŸ” [NAS-SEARCH] Delegating to central PathResolver for version: ${version}`);

      // ì¤‘ì•™ ì„œë¹„ìŠ¤ë¡œ ì•„í‹°íŒ©íŠ¸ ê²€ìƒ‰ ìœ„ì„
      const artifacts = await pathResolver.findArtifactsByVersion(version, null, pattern);

      logger.info(`ğŸ” [NAS-SEARCH] Central service found ${artifacts.length} artifacts for version ${version}`);
      return artifacts;

    } catch (error) {
      logger.error(`Failed to search artifacts by version ${version}:`, error.message);
      // í´ë°±: ê¸°ì¡´ ê²€ìƒ‰ ë°©ì‹
      return this.fallbackArtifactSearch(version, pattern);
    }
  }

  /**
   * í´ë°± ì•„í‹°íŒ©íŠ¸ ê²€ìƒ‰ (ê¸°ì¡´ ë°©ì‹)
   */
  async fallbackArtifactSearch(version, pattern = null) {
    logger.info(`ğŸ” [FALLBACK-SEARCH] Starting fallback search for version: ${version}`);
    
    // ê¸°ì¡´ ê²€ìƒ‰ ë¡œì§ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    const cleanVersion = version.startsWith('mr') ? version.substring(2) : version;
    const searchPaths = [
      `release_version/release/product/mr${cleanVersion}`,
      `release_version/release/product/${version}`,
      `release_version/release/product/${cleanVersion}`,
      `release/product/mr${cleanVersion}`,
      `release/product/${version}`,    
      `release/${version}`,
      `${version}`,
    ];

    const allArtifacts = [];

    for (const searchPath of searchPaths) {
      try {
        const allItems = await this.listDirectory(searchPath);

        for (const dirName of allItems) {
          if (dirName.match(/^\d{6}$/)) {
            try {
              const datePath = path.posix.join(searchPath, dirName);
              const dirInfo = await this.getFileInfo(datePath);
              if (!dirInfo.isDirectory) continue;

              const buildItems = await this.listDirectory(datePath);

              for (const buildDirName of buildItems) {
                if (buildDirName.match(/^\d+$/)) {
                  try {
                    const buildPath = path.posix.join(datePath, buildDirName);
                    const buildDirInfo = await this.getFileInfo(buildPath);
                    if (!buildDirInfo.isDirectory) continue;

                    const artifactFiles = await this.searchFiles(buildPath);

                    const compressedFiles = artifactFiles.filter(file => {
                      if (!file.name.match(/\.(tar\.gz|zip|7z|enc\.tar\.gz)$/i)) {
                        return false;
                      }

                      if (pattern) {
                        return file.name.toLowerCase().startsWith(pattern.toLowerCase());
                      }

                      return true;
                    });

                    for (const file of compressedFiles) {
                      allArtifacts.push({
                        filename: file.name,
                        filePath: file.path,
                        nasPath: file.path,
                        fileSize: file.size,
                        lastModified: file.modified,
                        buildNumber: buildDirName,
                        version: version,
                        searchPath: buildPath,
                        verified: true,
                      });
                    }
                  } catch (error) {
                    logger.warn(`Failed to process build directory ${buildDirName}:`, error.message);
                  }
                }
              }
            } catch (error) {
              logger.warn(`Failed to process date directory ${dirName}:`, error.message);
            }
          }
        }
      } catch (searchError) {
        logger.warn(`ğŸ” [FALLBACK-SEARCH] No artifacts found in path ${searchPath}: ${searchError.message}`);
      }
    }

    logger.info(`ğŸ” [FALLBACK-SEARCH] Fallback search completed. Found ${allArtifacts.length} artifacts`);
    return allArtifacts;
  }

  /**
   * ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
   */
  async directoryExists(dirPath) {
    try {
      const fileInfo = await this.getFileInfo(dirPath);
      return fileInfo.isDirectory;
    } catch (error) {
      return false;
    }
  }

  /**
   * ì—…ë¡œë“œ ê²½ë¡œ ê²€ì¦ ë° ì •ê·œí™”
   */
  validateAndNormalizeUploadPath(targetPath) {
    if (!targetPath || typeof targetPath !== 'string') {
      return '/release_version/release/upload';
    }

    let normalizedPath = targetPath.trim();

    // UNC ê²½ë¡œ ì²˜ë¦¬ (\\nas.roboetech.com\release_version -> /release_version)
    if (normalizedPath.startsWith('\\\\nas.roboetech.com\\')) {
      // UNC ê²½ë¡œì—ì„œ ê³µìœ  í´ë” ë¶€ë¶„ë§Œ ì¶”ì¶œ
      normalizedPath = normalizedPath.replace('\\\\nas.roboetech.com\\', '/');
      normalizedPath = normalizedPath.replace(/\\/g, '/');
    } else {
      // ë°±ìŠ¬ë˜ì‹œë¥¼ ìŠ¬ë˜ì‹œë¡œ ë³€í™˜
      normalizedPath = normalizedPath.replace(/\\/g, '/');
    }

    // ê²½ë¡œ ì •ë¦¬
    normalizedPath = normalizedPath.replace(/\/+/g, '/'); // ì—°ì†ëœ ìŠ¬ë˜ì‹œ ì œê±°

    // í—ˆìš©ë˜ì§€ ì•ŠëŠ” ê²½ë¡œ íŒ¨í„´ ì²´í¬
    const forbiddenPatterns = [
      /\.\./,           // ìƒìœ„ ë””ë ‰í† ë¦¬ ì ‘ê·¼
      /\/etc\//,        // ì‹œìŠ¤í…œ ë””ë ‰í† ë¦¬
      /\/usr\//,        // ì‹œìŠ¤í…œ ë””ë ‰í† ë¦¬
      /\/var\//,        // ì‹œìŠ¤í…œ ë””ë ‰í† ë¦¬
      /\/root\//,       // ë£¨íŠ¸ ë””ë ‰í† ë¦¬
      /\/volume\d+\//,  // volume ê²½ë¡œ ì§ì ‘ ì ‘ê·¼ ê¸ˆì§€
    ];

    for (const pattern of forbiddenPatterns) {
      if (pattern.test(normalizedPath)) {
        throw new AppError('ì—…ë¡œë“œ ê²½ë¡œê°€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.', 400);
      }
    }

    // Synology FileStation APIëŠ” ê³µìœ  í´ë”ëª…ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ë¡œ ì‚¬ìš©
    // /volume1/ ì ‘ë‘ì–´ê°€ ìˆìœ¼ë©´ ì œê±° (APIì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
    if (normalizedPath.startsWith('/volume1/')) {
      normalizedPath = normalizedPath.replace('/volume1/', '/');
    }

    // release_version ê³µìœ  í´ë”ê°€ ê¸°ë³¸ ê²½ë¡œ
    if (!normalizedPath.startsWith('/release_version/')) {
      if (normalizedPath.startsWith('/')) {
        // ë‹¤ë¥¸ ì ˆëŒ€ê²½ë¡œì¸ ê²½ìš° release_version í•˜ìœ„ë¡œ ì´ë™
        normalizedPath = '/release_version' + normalizedPath;
      } else {
        // ìƒëŒ€ê²½ë¡œì¸ ê²½ìš° ê¸°ë³¸ ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ì— ì¶”ê°€
        normalizedPath = '/release_version/release/upload/' + normalizedPath;
      }
    }

    // ê¸°ë³¸ ì—…ë¡œë“œ ê²½ë¡œ ì„¤ì • (ê²½ë¡œê°€ ê³µìœ  í´ë”ë§Œ ì§€ì •ëœ ê²½ìš°)
    if (normalizedPath === '/release_version' || normalizedPath === '/release_version/') {
      normalizedPath = '/release_version/release/upload';
    }

    // ëì— ìŠ¬ë˜ì‹œê°€ ìˆìœ¼ë©´ ì œê±° (íŒŒì¼ëª…ì´ ë¶™ì„ ê²ƒì´ë¯€ë¡œ)
    if (normalizedPath.endsWith('/')) {
      normalizedPath = normalizedPath.slice(0, -1);
    }

    return normalizedPath;
  }

  /**
   * ë‹¤ìš´ë¡œë“œ URL ìƒì„± (ë‹¤ìš´ë¡œë“œ ì„œë¹„ìŠ¤ ì§€ì›)
   */
  async createDirectDownloadUrl(filePath, options = {}) {
    try {
      await this.ensureConnection();
      return await this.synologyApiService.createDirectDownloadUrl(filePath, options);
    } catch (error) {
      logger.error(`Failed to create direct download URL for ${filePath}:`, error.message);
      return { success: false, error: error.message };
    }
  }

  /**
   * íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„± (ë‹¤ìš´ë¡œë“œ ì„œë¹„ìŠ¤ ì§€ì›)
   */
  async createFileDownloadLink(filePath) {
    try {
      await this.ensureConnection();
      return await this.synologyApiService.createFileDownloadLink(filePath);
    } catch (error) {
      logger.error(`Failed to create file download link for ${filePath}:`, error.message);
      return { success: false, error: error.message };
    }
  }

  /**
   * ê²½ë¡œ ì •ê·œí™” (ë‹¤ìš´ë¡œë“œ ì„œë¹„ìŠ¤ ì§€ì›)
   */
  normalizePath(path) {
    return this.synologyApiService.normalizePath(path);
  }

  /**
   * Product í•˜ìœ„ ì „ì²´ ìŠ¤ìº” - ëª¨ë“  ë°°í¬ íŒŒì¼ ê²€ìƒ‰
   */
  async fullProductScan() {
    const startTime = Date.now();
    let scannedVersions = 0;
    let errorCount = 0;
    
    try {
      logger.info('ğŸ” [FULL-SCAN] Starting full product scan...');
      await this.ensureConnection();

      const basePath = '/release_version/release/product';
      const allArtifacts = [];
      const scanErrors = [];

      // 1. product í•˜ìœ„ ëª¨ë“  ë²„ì „ í´ë” ìŠ¤ìº”
      logger.info(`ğŸ” [FULL-SCAN] Listing directories in: ${basePath}`);
      const versionFolders = await this.synologyApiService.listDirectoryFiles(basePath);
      
      if (!versionFolders.success) {
        const errorMsg = `Failed to list product directories: ${versionFolders.error || 'Unknown error'}`;
        logger.error(`ğŸ” [FULL-SCAN] ${errorMsg}`);
        throw new Error(errorMsg);
      }
      
      if (!versionFolders.files || versionFolders.files.length === 0) {
        logger.warn(`ğŸ” [FULL-SCAN] No version folders found in ${basePath}`);
        return {
          success: true,
          artifacts: [],
          scannedAt: new Date(),
          totalCount: 0,
          scanDuration: Date.now() - startTime,
          scannedVersions: 0,
          errors: ['No version folders found']
        };
      }

      logger.info(`ğŸ” [FULL-SCAN] Found ${versionFolders.files.length} items in product directory`);
      const validVersionFolders = versionFolders.files.filter(f => f.name.startsWith('mr'));
      logger.info(`ğŸ” [FULL-SCAN] Found ${validVersionFolders.length} valid version folders`);

      if (validVersionFolders.length === 0) {
        logger.warn('ğŸ” [FULL-SCAN] No valid version folders (starting with "mr") found');
        return {
          success: true,
          artifacts: [],
          scannedAt: new Date(),
          totalCount: 0,
          scanDuration: Date.now() - startTime,
          scannedVersions: 0,
          errors: ['No valid version folders found']
        };
      }

      for (const versionFolder of validVersionFolders) {
        const versionPath = `${basePath}/${versionFolder.name}`;
        logger.info(`ğŸ” [FULL-SCAN] Scanning version folder: ${versionFolder.name}`);
        scannedVersions++;

        try {
          // 2. ë²„ì „ í´ë” í•˜ìœ„ ë‚ ì§œ í´ë”ë“¤ ìŠ¤ìº”
          const dateFolders = await this.synologyApiService.listDirectoryFiles(versionPath);
          
          if (!dateFolders.success) {
            const error = `Failed to list date folders in ${versionPath}: ${dateFolders.error || 'Unknown error'}`;
            logger.warn(`ğŸ” [FULL-SCAN] ${error}`);
            scanErrors.push(error);
            errorCount++;
            continue;
          }
          
          if (dateFolders.success && dateFolders.files && dateFolders.files.length > 0) {
            const validDateFolders = dateFolders.files.filter(f => f.name.match(/^\d{6}$/));
            logger.info(`ğŸ” [FULL-SCAN] Found ${validDateFolders.length} valid date folders in ${versionFolder.name}`);
            
            for (const dateFolder of validDateFolders) {
              const datePath = `${versionPath}/${dateFolder.name}`;

              try {
                // 3. ë‚ ì§œ í´ë” í•˜ìœ„ ë¹Œë“œë²ˆí˜¸ í´ë”ë“¤ ìŠ¤ìº”
                const buildFolders = await this.synologyApiService.listDirectoryFiles(datePath);
                
                if (!buildFolders.success) {
                  const error = `Failed to list build folders in ${datePath}: ${buildFolders.error || 'Unknown error'}`;
                  logger.warn(`ğŸ” [FULL-SCAN] ${error}`);
                  scanErrors.push(error);
                  errorCount++;
                  continue;
                }
                
                if (buildFolders.success && buildFolders.files && buildFolders.files.length > 0) {
                  const validBuildFolders = buildFolders.files.filter(f => f.name.match(/^\d+$/));
                  logger.debug(`ğŸ” [FULL-SCAN] Found ${validBuildFolders.length} valid build folders in ${dateFolder.name}`);
                  
                  for (const buildFolder of validBuildFolders) {
                    const buildPath = `${datePath}/${buildFolder.name}`;

                    try {
                      // 4. ë¹Œë“œ í´ë” ë‚´ íŒŒì¼ë“¤ ìŠ¤ìº”
                      const buildFiles = await this.synologyApiService.listDirectoryFiles(buildPath);
                      
                      if (!buildFiles.success) {
                        const error = `Failed to list files in ${buildPath}: ${buildFiles.error || 'Unknown error'}`;
                        logger.warn(`ğŸ” [FULL-SCAN] ${error}`);
                        scanErrors.push(error);
                        errorCount++;
                        continue;
                      }
                      
                      if (buildFiles.success && buildFiles.files && buildFiles.files.length > 0) {
                        const artifactFiles = buildFiles.files.filter(f => 
                          !f.isdir && f.name.match(/\.(tar\.gz|enc\.tar\.gz)$/i)
                        );
                        
                        for (const file of artifactFiles) {
                          try {
                            const { getPathResolver } = require('./pathResolver');
                            const pathResolver = getPathResolver();
                            const fileType = pathResolver.classifyFileType(file.name);

                            if (fileType) {
                              // íŒŒì¼ ì •ë³´ ê²€ì¦
                              if (!file.name || typeof file.name !== 'string') {
                                logger.warn(`ğŸ” [FULL-SCAN] Invalid file name in ${buildPath}`);
                                continue;
                              }
                              
                              if (!file.mtime || isNaN(file.mtime)) {
                                logger.warn(`ğŸ” [FULL-SCAN] Invalid mtime for file ${file.name}`);
                              }

                              const artifact = {
                                filename: file.name,
                                fullPath: `/${buildPath}/${file.name}`,
                                version: pathResolver.extractVersion(versionFolder.name) || versionFolder.name.replace('mr', ''),
                                fileType: fileType,
                                fileSize: file.size || 0,
                                modifiedTime: file.mtime ? new Date(file.mtime * 1000) : new Date(),
                                buildDate: dateFolder.name,
                                buildNumber: buildFolder.name,
                                versionFolder: versionFolder.name,
                                nasPath: `${buildPath}/${file.name}`,
                                scannedAt: new Date(),
                              };

                              allArtifacts.push(artifact);
                              logger.debug(`ğŸ” [FULL-SCAN] Added artifact: ${file.name} (${fileType})`);
                            } else {
                              logger.debug(`ğŸ” [FULL-SCAN] Unclassified file: ${file.name}`);
                            }
                          } catch (artifactError) {
                            const error = `Failed to process artifact ${file.name}: ${artifactError.message}`;
                            logger.warn(`ğŸ” [FULL-SCAN] ${error}`);
                            scanErrors.push(error);
                            errorCount++;
                          }
                        }
                      }
                    } catch (error) {
                      const errorMsg = `Failed to scan build folder ${buildPath}: ${error.message}`;
                      logger.warn(`ğŸ” [FULL-SCAN] ${errorMsg}`);
                      scanErrors.push(errorMsg);
                      errorCount++;
                    }
                  }
                }
              } catch (error) {
                const errorMsg = `Failed to scan date folder ${datePath}: ${error.message}`;
                logger.warn(`ğŸ” [FULL-SCAN] ${errorMsg}`);
                scanErrors.push(errorMsg);
                errorCount++;
              }
            }
          }
        } catch (error) {
          const errorMsg = `Failed to scan version folder ${versionPath}: ${error.message}`;
          logger.error(`ğŸ” [FULL-SCAN] ${errorMsg}`);
          scanErrors.push(errorMsg);
          errorCount++;
        }
      }

      const scanDuration = Date.now() - startTime;
      logger.info(`ğŸ” [FULL-SCAN] Scan completed in ${scanDuration}ms`);
      logger.info(`ğŸ” [FULL-SCAN] Results: ${allArtifacts.length} artifacts, ${scannedVersions} versions, ${errorCount} errors`);
      
      if (scanErrors.length > 0) {
        logger.warn(`ğŸ” [FULL-SCAN] Scan completed with ${scanErrors.length} errors:`);
        scanErrors.slice(0, 5).forEach(error => logger.warn(`  - ${error}`));
        if (scanErrors.length > 5) {
          logger.warn(`  ... and ${scanErrors.length - 5} more errors`);
        }
      }
      
      return {
        success: true,
        artifacts: allArtifacts,
        scannedAt: new Date(),
        totalCount: allArtifacts.length,
        scanDuration,
        scannedVersions,
        errorCount,
        errors: scanErrors.length > 0 ? scanErrors : undefined
      };

    } catch (error) {
      const scanDuration = Date.now() - startTime;
      logger.error(`ğŸ” [FULL-SCAN] Full product scan failed after ${scanDuration}ms:`, {
        error: error.message,
        stack: error.stack,
        scannedVersions,
        errorCount
      });
      
      return {
        success: false,
        error: error.message,
        artifacts: [],
        scannedAt: new Date(),
        totalCount: 0,
        scanDuration,
        scannedVersions,
        errorCount
      };
    }
  }

  /**
   * ì¦ë¶„ ìŠ¤ìº” - íŠ¹ì • ë²„ì „ë§Œ ì¬ìŠ¤ìº”
   */
  async incrementalScan(version) {
    try {
      logger.info(`ğŸ” [INCREMENTAL-SCAN] Starting incremental scan for version: ${version}`);
      await this.ensureConnection();

      const versionPath = `/release_version/release/product/mr${version}`;
      const artifacts = [];

      // í•´ë‹¹ ë²„ì „ í´ë”ë§Œ ìŠ¤ìº” (fullProductScanì˜ ë¡œì§ì„ ì¬ì‚¬ìš©)
      const dateFolders = await this.synologyApiService.listDirectoryFiles(versionPath);
      
      if (dateFolders.success && dateFolders.files) {
        for (const dateFolder of dateFolders.files) {
          // ë‚ ì§œ í´ë”ëª… íŒ¨í„´ìœ¼ë¡œ íŒë‹¨ (YYMMDD í˜•ì‹)
          if (!dateFolder.name.match(/^\d{6}$/)) continue;

          const datePath = `${versionPath}/${dateFolder.name}`;
          const buildFolders = await this.synologyApiService.listDirectoryFiles(datePath);
          
          if (buildFolders.success && buildFolders.files) {
            for (const buildFolder of buildFolders.files) {
              // ë¹Œë“œë²ˆí˜¸ í´ë”ëª… íŒ¨í„´ìœ¼ë¡œ íŒë‹¨ (ìˆ«ìë¡œë§Œ êµ¬ì„±)
              if (!buildFolder.name.match(/^\d+$/)) continue;

              const buildPath = `${datePath}/${buildFolder.name}`;
              const buildFiles = await this.synologyApiService.listDirectoryFiles(buildPath);
              
              if (buildFiles.success && buildFiles.files) {
                for (const file of buildFiles.files) {
                  if (file.isdir || !file.name.match(/\.(tar\.gz|enc\.tar\.gz)$/i)) continue;

                  const { getPathResolver } = require('./pathResolver');
                  const pathResolver = getPathResolver();
                  const fileType = pathResolver.classifyFileType(file.name);

                  if (fileType) {
                    const artifact = {
                      filename: file.name,
                      fullPath: `/${buildPath}/${file.name}`,
                      version: version,
                      fileType: fileType,
                      fileSize: file.size || 0,
                      modifiedTime: new Date(file.mtime * 1000),
                      buildDate: dateFolder.name,
                      buildNumber: buildFolder.name,
                      versionFolder: `mr${version}`,
                      nasPath: `${buildPath}/${file.name}`,
                      scannedAt: new Date(),
                    };

                    artifacts.push(artifact);
                  }
                }
              }
            }
          }
        }
      }

      logger.info(`ğŸ” [INCREMENTAL-SCAN] Found ${artifacts.length} artifacts for version ${version}`);
      return {
        success: true,
        artifacts: artifacts,
        version: version,
        scannedAt: new Date(),
      };

    } catch (error) {
      logger.error(`ğŸ” [INCREMENTAL-SCAN] Incremental scan failed for version ${version}:`, error.message);
      return {
        success: false,
        error: error.message,
        artifacts: [],
      };
    }
  }

  /**
   * íŒŒì¼ ì—…ë¡œë“œ - Synology API ì‚¬ìš©
   */
  async uploadFile(fileBuffer, targetPath, originalName) {
    logger.info(`NAS uploadFile ìš”ì²­ - íŒŒì¼: ${originalName}, ê²½ë¡œ: ${targetPath}`);

    try {
      // ì—…ë¡œë“œ ê²½ë¡œ ê²€ì¦ ë° ì •ê·œí™”
      const normalizedPath = this.validateAndNormalizeUploadPath(targetPath);

      logger.info('íŒŒì¼ ì—…ë¡œë“œ ê²½ë¡œ ë³€í™˜:');
      logger.info(`- ì›ë³¸ ê²½ë¡œ: ${targetPath}`);
      logger.info(`- ì •ê·œí™”ëœ ê²½ë¡œ: ${normalizedPath}`);

      // Synology APIë¥¼ í†µí•œ íŒŒì¼ ì—…ë¡œë“œ
      await this.ensureConnection();
      const uploadResult = await this.synologyApiService.uploadFile(fileBuffer, normalizedPath, originalName);

      if (uploadResult.success) {
        logger.info('Synology APIë¥¼ í†µí•œ íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ:');
        logger.info(`- íŒŒì¼ëª…: ${uploadResult.filename}`);
        logger.info(`- ì—…ë¡œë“œ ê²½ë¡œ: ${uploadResult.path}`);
        logger.info(`- íŒŒì¼ í¬ê¸°: ${uploadResult.size} bytes`);

        return {
          success: true,
          path: uploadResult.path,
          filename: uploadResult.filename,
          size: uploadResult.size,
          method: 'synology-api',
        };
      } else {
        throw new Error(`Synology API ì—…ë¡œë“œ ì‹¤íŒ¨: ${uploadResult.error}`);
      }

    } catch (error) {
      logger.error(`íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: ${error.message}`);
      logger.error(`Error stack: ${error.stack}`);
      throw new AppError(`File upload failed: ${error.message}`, 500);
    }
  }

  /**
   * ìŠ¤ìº” ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
   */
  async saveArtifactsToDatabase(artifacts, scanType = 'full') {
    try {
      const { query } = require('../config/database');
      
      // ìŠ¤ìº” ë¡œê·¸ ìƒì„±
      const scanLogResult = await query(`
        INSERT INTO nas_scan_logs (scan_type, scan_status, total_count, started_at)
        VALUES ($1, 'running', $2, CURRENT_TIMESTAMP)
        RETURNING id
      `, [scanType, artifacts.length]);
      
      const scanLogId = scanLogResult.rows[0].id;
      let newCount = 0;
      let updatedCount = 0;
      let errorCount = 0;
      
      for (const artifact of artifacts) {
        try {
          // UPSERT ì‘ì—…
          const result = await query(`
            INSERT INTO nas_artifacts (
              filename, full_path, nas_path, file_size, version, version_folder,
              build_date, build_number, file_type, modified_time, scanned_at,
              scan_type, search_path, verified
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
            ON CONFLICT (full_path) DO UPDATE SET
              file_size = EXCLUDED.file_size,
              modified_time = EXCLUDED.modified_time,
              scanned_at = EXCLUDED.scanned_at,
              last_verified_at = CURRENT_TIMESTAMP,
              scan_type = EXCLUDED.scan_type,
              verified = EXCLUDED.verified,
              updated_at = CURRENT_TIMESTAMP
            RETURNING (xmax = 0) as is_new
          `, [
            artifact.filename,
            artifact.fullPath,
            artifact.nasPath,
            artifact.fileSize,
            artifact.version,
            artifact.versionFolder,
            artifact.buildDate,
            artifact.buildNumber,
            artifact.fileType,
            artifact.modifiedTime,
            artifact.scannedAt,
            scanType,
            artifact.searchPath || null,
            artifact.verified || true
          ]);
          
          if (result.rows[0].is_new) {
            newCount++;
          } else {
            updatedCount++;
          }
          
        } catch (error) {
          logger.error(`Failed to save artifact ${artifact.filename}:`, error.message);
          errorCount++;
        }
      }
      
      // ìŠ¤ìº” ë¡œê·¸ ì—…ë°ì´íŠ¸
      await query(`
        UPDATE nas_scan_logs 
        SET scan_status = 'completed',
            new_files_count = $1,
            updated_files_count = $2,
            error_count = $3,
            completed_at = CURRENT_TIMESTAMP
        WHERE id = $4
      `, [newCount, updatedCount, errorCount, scanLogId]);
      
      logger.info(`ğŸ” [DB-SAVE] Saved ${artifacts.length} artifacts: ${newCount} new, ${updatedCount} updated, ${errorCount} errors`);
      
      return {
        scanLogId,
        newCount,
        updatedCount,
        errorCount,
        totalCount: artifacts.length
      };
      
    } catch (error) {
      logger.error('Failed to save artifacts to database:', error.message);
      throw error;
    }
  }

  /**
   * ì¦ë¶„ ìŠ¤ìº” - ìµœê·¼ ë³€ê²½ëœ íŒŒì¼ë§Œ ìŠ¤ìº”
   */
  async incrementalScan(options = {}) {
    const startTime = Date.now();
    const {
      sinceHours = 24,
      specificVersions = null,
      forceRescan = false
    } = options;
    
    try {
      logger.info(`ğŸ” [INCREMENTAL-SCAN] Starting incremental scan (since ${sinceHours}h ago)`);
      await this.ensureConnection();

      // ê¸°ì¤€ ì‹œê°„ ê³„ì‚°
      const cutoffTime = new Date(Date.now() - (sinceHours * 60 * 60 * 1000));
      logger.info(`ğŸ” [INCREMENTAL-SCAN] Cutoff time: ${cutoffTime.toISOString()}`);

      const basePath = '/release_version/release/product';
      const newArtifacts = [];
      const scanErrors = [];
      let scannedVersions = 0;
      let errorCount = 0;

      // ë²„ì „ í´ë” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
      const versionFolders = await this.synologyApiService.listDirectoryFiles(basePath);
      
      if (!versionFolders.success) {
        throw new Error(`Failed to list product directories: ${versionFolders.error}`);
      }

      let targetVersions = versionFolders.files.filter(f => f.name.startsWith('mr'));
      
      // íŠ¹ì • ë²„ì „ë§Œ ìŠ¤ìº”
      if (specificVersions && specificVersions.length > 0) {
        targetVersions = targetVersions.filter(f => 
          specificVersions.some(v => f.name === `mr${v}` || f.name === v)
        );
      }

      logger.info(`ğŸ” [INCREMENTAL-SCAN] Scanning ${targetVersions.length} versions`);

      for (const versionFolder of targetVersions) {
        const versionPath = `${basePath}/${versionFolder.name}`;
        scannedVersions++;

        try {
          // ë‚ ì§œ í´ë”ë“¤ ê²€ì‚¬
          const dateFolders = await this.synologyApiService.listDirectoryFiles(versionPath);
          
          if (!dateFolders.success) {
            const error = `Failed to list date folders in ${versionPath}: ${dateFolders.error}`;
            scanErrors.push(error);
            errorCount++;
            continue;
          }

          // ìµœê·¼ ë‚ ì§œ í´ë”ë§Œ í•„í„°ë§ (YYMMDD í˜•ì‹)
          const recentDateFolders = dateFolders.files
            .filter(f => f.name.match(/^\d{6}$/))
            .filter(f => {
              if (forceRescan) return true;
              
              // ë‚ ì§œ í´ë” ìˆ˜ì • ì‹œê°„ í™•ì¸
              return f.mtime && new Date(f.mtime * 1000) > cutoffTime;
            });

          logger.info(`ğŸ” [INCREMENTAL-SCAN] ${versionFolder.name}: ${recentDateFolders.length} recent date folders`);

          for (const dateFolder of recentDateFolders) {
            const datePath = `${versionPath}/${dateFolder.name}`;

            try {
              const buildFolders = await this.synologyApiService.listDirectoryFiles(datePath);
              
              if (buildFolders.success && buildFolders.files) {
                const validBuildFolders = buildFolders.files.filter(f => f.name.match(/^\d+$/));
                
                for (const buildFolder of validBuildFolders) {
                  const buildPath = `${datePath}/${buildFolder.name}`;

                  try {
                    const buildFiles = await this.synologyApiService.listDirectoryFiles(buildPath);
                    
                    if (buildFiles.success && buildFiles.files) {
                      const artifactFiles = buildFiles.files.filter(f => 
                        !f.isdir && f.name.match(/\.(tar\.gz|enc\.tar\.gz)$/i)
                      );
                      
                      for (const file of artifactFiles) {
                        // íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸
                        const fileModTime = new Date(file.mtime * 1000);
                        if (!forceRescan && fileModTime <= cutoffTime) {
                          continue;
                        }

                        const { getPathResolver } = require('./pathResolver');
                        const pathResolver = getPathResolver();
                        const fileType = pathResolver.classifyFileType(file.name);

                        if (fileType) {
                          const artifact = {
                            filename: file.name,
                            fullPath: `/${buildPath}/${file.name}`,
                            version: pathResolver.extractVersion(versionFolder.name) || versionFolder.name.replace('mr', ''),
                            fileType: fileType,
                            fileSize: file.size || 0,
                            modifiedTime: fileModTime,
                            buildDate: dateFolder.name,
                            buildNumber: buildFolder.name,
                            versionFolder: versionFolder.name,
                            nasPath: `${buildPath}/${file.name}`,
                            scannedAt: new Date(),
                          };

                          newArtifacts.push(artifact);
                        }
                      }
                    }
                  } catch (error) {
                    const errorMsg = `Failed to scan build folder ${buildPath}: ${error.message}`;
                    scanErrors.push(errorMsg);
                    errorCount++;
                  }
                }
              }
            } catch (error) {
              const errorMsg = `Failed to scan date folder ${datePath}: ${error.message}`;
              scanErrors.push(errorMsg);
              errorCount++;
            }
          }
        } catch (error) {
          const errorMsg = `Failed to scan version folder ${versionPath}: ${error.message}`;
          scanErrors.push(errorMsg);
          errorCount++;
        }
      }

      const scanDuration = Date.now() - startTime;
      
      logger.info(`ğŸ” [INCREMENTAL-SCAN] Completed in ${scanDuration}ms`);
      logger.info(`ğŸ” [INCREMENTAL-SCAN] Results: ${newArtifacts.length} new artifacts, ${scannedVersions} versions, ${errorCount} errors`);

      return {
        success: true,
        artifacts: newArtifacts,
        scannedAt: new Date(),
        totalCount: newArtifacts.length,
        scanDuration,
        scannedVersions,
        errorCount,
        scanType: 'incremental',
        cutoffTime: cutoffTime.toISOString(),
        errors: scanErrors.length > 0 ? scanErrors : undefined
      };

    } catch (error) {
      const scanDuration = Date.now() - startTime;
      logger.error(`ğŸ” [INCREMENTAL-SCAN] Failed after ${scanDuration}ms:`, error.message);
      
      return {
        success: false,
        error: error.message,
        artifacts: [],
        scannedAt: new Date(),
        totalCount: 0,
        scanDuration,
        scannedVersions,
        errorCount: errorCount + 1,
        scanType: 'incremental'
      };
    }
  }

  /**
   * ì „ì²´ ìŠ¤ìº” í›„ DB ì €ì¥
   */
  async fullProductScanAndSave() {
    try {
      // ì „ì²´ ìŠ¤ìº” ì‹¤í–‰
      const scanResult = await this.fullProductScan();
      
      if (scanResult.success && scanResult.artifacts.length > 0) {
        // DBì— ì €ì¥
        const saveResult = await this.saveArtifactsToDatabase(scanResult.artifacts, 'full');
        
        return {
          ...scanResult,
          database: saveResult
        };
      }
      
      return scanResult;
    } catch (error) {
      logger.error('Full scan and save failed:', error.message);
      throw error;
    }
  }

  /**
   * ì¦ë¶„ ìŠ¤ìº” í›„ DB ì €ì¥
   */
  async incrementalScanAndSave(options = {}) {
    try {
      // ì¦ë¶„ ìŠ¤ìº” ì‹¤í–‰
      const scanResult = await this.incrementalScan(options);
      
      if (scanResult.success && scanResult.artifacts.length > 0) {
        // DBì— ì €ì¥
        const saveResult = await this.saveArtifactsToDatabase(scanResult.artifacts, 'incremental');
        
        return {
          ...scanResult,
          database: saveResult
        };
      }
      
      return scanResult;
    } catch (error) {
      logger.error('Incremental scan and save failed:', error.message);
      throw error;
    }
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
let nasServiceInstance = null;

/**
 * NAS ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
 */
function getNASService() {
  if (!nasServiceInstance) {
    nasServiceInstance = new NASService();
  }
  return nasServiceInstance;
}

module.exports = {
  NASService,
  getNASService,
};
